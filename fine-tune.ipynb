{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# designate root path for the data\n",
    "DATA_ROOT_PATH = \"./data\"\n",
    "\n",
    "# designate path for each dataset files\n",
    "LYRIC_PATH = os.path.join(DATA_ROOT_PATH, \"lyrics_kor.txt\")\n",
    "BILLBOARD_PATH = os.path.join(DATA_ROOT_PATH, \"rawdata_김지훈_201500844.tsv\")\n",
    "GEULSTAGRAM_PATH = os.path.join(DATA_ROOT_PATH, \"geulstagram.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# read txt file from line by line\n",
    "def read_txt(path):\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "    return lines\n",
    "\n",
    "# make sampling function from the list\n",
    "def sampling(list_lines:list, n:int) -> list:\n",
    "    # sampling\n",
    "    list_lines = np.random.choice(list_lines, n)\n",
    "    list_lines = list(list_lines)\n",
    "    return list_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82989"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read dataset from poetic_sentences_kor.txt\n",
    "path = os.path.join(DATA_ROOT_PATH, \"poetic_sentences_kor.txt\")\n",
    "list_loaded = read_txt(path)\n",
    "len(list_loaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66872 0.8057935389027462\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['아픈 사랑하느라 고생 많았다.\\n',\n",
       " '늘 그대 옆에 있는데\\n',\n",
       " '모두 다 아름답게 타오르던 불꽃\\n',\n",
       " '고개를 숙인 채\\n',\n",
       " '해가 길어\\n',\n",
       " '사랑은 날개를 펼쳐야 할 때가 있다.\\n',\n",
       " '남들은 우습다 유치하다 한들 나는 믿는다 영원한 영혼을 죽음 너머 그곳을. 그렇다고 믿자.\\n',\n",
       " '되려 화를 내면서\\n',\n",
       " '나의 평안을 나의 사랑을 별에 기도해\\n',\n",
       " '차돌 깨진 그릇을 다시 붙여보았다\\n',\n",
       " '검푸른 겨울바다\\n',\n",
       " '그녀가 처음으로 울던 날내곁을 떠나갔다네\\n',\n",
       " '잠잘 때 말곤 내가 나를 위해 쓰는 시간이 없네\\n',\n",
       " '결국 우리들 자신에게 달려있다 아리스토텔레스 아재 글\\n',\n",
       " '내겐 덤이라오\\n',\n",
       " '마음의 문을 활짝 열고\\n',\n",
       " '그런데 또 다른 하나의 요구를 폭력으로 짓밟는다면 하나에게만 자유가 있게 되지\\n',\n",
       " '권 쩨 같으랴.\\n',\n",
       " '서른엔 승 행복해오 했다 수\\n',\n",
       " '얼마나 더 먼 곳을 바라볼 수 있을지\\n']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get proportion of sentences where length is between 1 and 52\n",
    "min_char_length = 5\n",
    "max_char_length = 52\n",
    "list_to_use = list(filter(lambda x: len(x) > min_char_length and len(x) < max_char_length, list_loaded))\n",
    "print(len(list_to_use) , len(list_to_use) / len(list_loaded))\n",
    "sampling(list_to_use, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "stopwords = []\n",
    "\n",
    "# make post_process function\n",
    "def post_process(list_lines:list) -> list:\n",
    "    # remove \\n\n",
    "    removed_lines = [line.strip() for line in list_lines]\n",
    "\n",
    "    # filter stopwords from the line item in list_lines using regex\n",
    "    if len(stopwords) > 0:\n",
    "        removed_lines = []\n",
    "        for line in list_lines:\n",
    "            for stopword in stopwords:\n",
    "                line = re.sub(stopword, '', line)\n",
    "            removed_lines.append(line)\n",
    "\n",
    "    # remove newlines\n",
    "    removed_lines = [sentence.replace('\\n', '') for sentence in removed_lines]\n",
    "\n",
    "    # strip whitespace\n",
    "    removed_lines = [sentence.strip() for sentence in removed_lines]\n",
    "\n",
    "    # remove one letter items\n",
    "    removed_lines = [sentence for sentence in removed_lines if len(sentence) > 1]\n",
    "\n",
    "    return removed_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66872\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['세 죽음의 카운트가 시작되었다.',\n",
       " '그리운 그대를 찾아서 떠나지',\n",
       " '아마 나이가 사람을 지혜롭게 하는 모양이지요',\n",
       " '지금 내 모습도 지금 내 상황도 모두 마음에 들지 않는다.',\n",
       " '음 반복되는 시간에 지쳐가 더 이상 함께 웃을 일도 없어 봄처럼 따뜻했던 그때가 좋았어',\n",
       " '제가 어렸을 때 시골에서 잔서 그런 걸 봤거든요.',\n",
       " '얼마 전에 먹은 거 왜 또 먹 냐고 하지 마',\n",
       " '그 언젠가 또 이곳에',\n",
       " '이우경 머물고 싶은 남자 떠나고 싶은 여자 중에서..',\n",
       " '사랑이 지니가면',\n",
       " '날씨가 더워서 혁헉 거릴 때도 있었지만 집에서는 시원하게 보낼 수 있어 좋았다.',\n",
       " '몸에 이상이 있는 사람이 장애인이 아니라 마음에 이상이 있는 사람이 진짜 장애인이다.',\n",
       " '잘 가라는 인사조차',\n",
       " '가슴 속에 무엇인가 아쉬움이 남지만',\n",
       " '나 홀로 외로이 걸으며',\n",
       " '사랑만 해주세요.',\n",
       " '그 끝이 당신에게 더 빨리 찾아올 수 있다.',\n",
       " '잘라라 루딘 루미 봄의 정원으로 오라 중에서..',\n",
       " '잘해줄 거야',\n",
       " '내가 울고 있었거든요']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_post_processed = post_process(list_to_use)\n",
    "print(len(list_post_processed))\n",
    "sampling(list_post_processed, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine maximum token length to pad in order to create batch\n",
    "- max_token_length is different from max_char_length.\n",
    "- max_token_length is based on input_ids of pretrained GPT2Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
      "The class this function is called from is 'PreTrainedTokenizerFast'.\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer, PreTrainedTokenizerFast\n",
    "\n",
    "model_dir = \"skt/ko-gpt-trinity-1.2B-v0.5\"\n",
    "\n",
    "# Load the Tokenizer: \"Fast\" means that the tokenizer code is written in Rust Lang\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained(\n",
    "    model_dir,\n",
    "    bos_token=\"<s>\",\n",
    "    eos_token=\"</s>\",\n",
    "    unk_token=\"<unk>\",\n",
    "    pad_token=\"<pad>\",\n",
    "    mask_token=\"<mask>\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the length of the individual items in tokenized input_ids\n",
    "tokenized_input_ids = tokenizer(list_post_processed).input_ids\n",
    "tokenized_length = [len(item) for item in tokenized_input_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# check the length distribution of the list with x ticks divided by 10 tokens\n",
    "plt.hist(tokenized_length, bins=np.arange(0, max(tokenized_length)+1, 10))\n",
    "print(max(tokenized_length)+1)\n",
    "plt.xlabel(\"Length of the sentence\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66872 0.8057935389027462\n"
     ]
    }
   ],
   "source": [
    "# get proportion of sentences where length is between 0 and 32\n",
    "min_token_length = 0\n",
    "max_token_length = 42\n",
    "list_between = list(filter(lambda x: x > min_token_length and x < max_token_length, tokenized_length))\n",
    "print(len(list_between) , len(list_between) / len(list_loaded))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
      "The class this function is called from is 'PreTrainedTokenizerFast'.\n"
     ]
    }
   ],
   "source": [
    "model_dir = \"skt/ko-gpt-trinity-1.2B-v0.5\"\n",
    "\n",
    "# https://huggingface.co/transformers/preprocessing.html\n",
    "# Load the Tokenizer: \"Fast\" means that the tokenizer code is written in Rust Lang\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained(\n",
    "    model_dir,\n",
    "    max_len = max_token_length,\n",
    "    padding='max_length',\n",
    "    add_special_tokens = True,\n",
    "    return_tensors=\"pt\",\n",
    "    truncation = True,\n",
    "    bos_token = \"<s>\",\n",
    "    eos_token = \"</s>\",\n",
    "    unk_token = \"<unk>\",\n",
    "    pad_token = \"<pad>\",\n",
    "    mask_token = \"<mask>\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define model configuration and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Config\n",
    "\n",
    "# set config and override with custom configuration\n",
    "config = GPT2Config.from_pretrained(model_dir)\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel\n",
    "\n",
    "# designate the model's name registered on huggingface: https://huggingface.co/skt/ko-gpt-trinity-1.2B-v0.5\n",
    "model_dir = \"skt/ko-gpt-trinity-1.2B-v0.5\"\n",
    "\n",
    "# Attach Language model Head to the pretrained GPT model\n",
    "model = GPT2LMHeadModel.from_pretrained(model_dir) # KoGPT3 shares the same structure as KoGPT2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(51200, 1920)\n",
       "    (wpe): Embedding(1024, 1920)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0): GPT2Block(\n",
       "        (ln_1): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): GPT2Block(\n",
       "        (ln_1): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): GPT2Block(\n",
       "        (ln_1): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): GPT2Block(\n",
       "        (ln_1): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): GPT2Block(\n",
       "        (ln_1): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): GPT2Block(\n",
       "        (ln_1): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): GPT2Block(\n",
       "        (ln_1): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): GPT2Block(\n",
       "        (ln_1): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): GPT2Block(\n",
       "        (ln_1): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): GPT2Block(\n",
       "        (ln_1): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): GPT2Block(\n",
       "        (ln_1): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): GPT2Block(\n",
       "        (ln_1): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (12): GPT2Block(\n",
       "        (ln_1): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (13): GPT2Block(\n",
       "        (ln_1): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (14): GPT2Block(\n",
       "        (ln_1): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (15): GPT2Block(\n",
       "        (ln_1): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (16): GPT2Block(\n",
       "        (ln_1): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (17): GPT2Block(\n",
       "        (ln_1): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (18): GPT2Block(\n",
       "        (ln_1): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (19): GPT2Block(\n",
       "        (ln_1): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (20): GPT2Block(\n",
       "        (ln_1): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (21): GPT2Block(\n",
       "        (ln_1): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (22): GPT2Block(\n",
       "        (ln_1): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (23): GPT2Block(\n",
       "        (ln_1): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1920, out_features=51200, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "# move the model to device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f9100c3c266b1cd71851c62951119892bad84809058d01f3493295f06be191a8"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('poet': pyenv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
