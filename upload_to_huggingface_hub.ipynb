{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://huggingface.co/transformers/model_sharing.html\n",
    "!huggingface-cli login "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model_directory = \"/Users/noopy/Documents/BERT-PROJECTS/kor-3-line-poetry/results/checkpoint-18200/\"\n",
    "\n",
    "from transformers import GPT2LMHeadModel\n",
    "\n",
    "# Attach Language model Head to the pretrained GPT model\n",
    "model = GPT2LMHeadModel.from_pretrained(saved_model_directory) # KoGPT3 shares the same structure as KoGPT2. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (2) will be pushed upstream.\n",
      "The progress bars may be unreliable.\n",
      "Upload file pytorch_model.bin:  35%|███▌      | 1.53G/4.35G [6:50:07<00:04, 749MB/s]"
     ]
    }
   ],
   "source": [
    "model.push_to_hub(\"KoGPT-Joong-2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'user_name': 'snoop2head', 'max_token_length': 42}\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from easydict import EasyDict\n",
    "\n",
    "# Initialize configuration\n",
    "CFG = EasyDict()\n",
    "\n",
    "# Train configuration\n",
    "CFG.user_name = \"snoop2head\"\n",
    "CFG.max_token_length = 42\n",
    "\n",
    "print(CFG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
      "The class this function is called from is 'PreTrainedTokenizerFast'.\n",
      "/opt/conda/lib/python3.8/site-packages/huggingface_hub/hf_api.py:715: FutureWarning: `create_repo` now takes `token` as an optional positional argument. Be sure to adapt your code!\n",
      "  warnings.warn(\n",
      "Cloning https://huggingface.co/snoop2head/KoGPT-Joong-2 into local empty directory.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f8ac474d04d44f4a24dd1e370b372b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Download file pytorch_model.bin:   0%|          | 4.24k/4.35G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6a3af24a0424cd1a330d88f2c77bb3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Clean file pytorch_model.bin:   0%|          | 1.00k/4.35G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To https://huggingface.co/snoop2head/KoGPT-Joong-2\n",
      "   f997df4..ca3e05e  main -> main\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://huggingface.co/snoop2head/KoGPT-Joong-2/commit/ca3e05e45c4fb513521282e5f5d86b6cf80a146f'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer, PreTrainedTokenizerFast, AutoTokenizer\n",
    "\n",
    "# https://huggingface.co/transformers/preprocessing.html\n",
    "# Load the Tokenizer: \"Fast\" means that the tokenizer code is written in Rust Lang\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained(\n",
    "    \"skt/ko-gpt-trinity-1.2B-v0.5\",\n",
    "    max_len = CFG.max_token_length,\n",
    "    padding='max_length',\n",
    "    add_special_tokens = True,\n",
    "    return_tensors=\"pt\",\n",
    "    truncation = True,\n",
    "    bos_token = \"<s>\",\n",
    "    eos_token = \"</s>\",\n",
    "    unk_token = \"<unk>\",\n",
    "    pad_token = \"<pad>\",\n",
    "    mask_token = \"<mask>\",\n",
    ")\n",
    "\n",
    "tokenizer.push_to_hub(\"KoGPT-Joong-2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c49faf493ce549abfe10b2ba130d6685c97f630b223f0053338a01200e3b08a8"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('korpoet': pyenv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
