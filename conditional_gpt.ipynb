{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "conditional_gpt",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0de2f9d2c343424cb85cd01f83be89a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8e64d363bc7f4282994a3977e210733b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3134ebd7f7054d1a82670d300e33ef1e",
              "IPY_MODEL_8bd427622f8e4c8cba2a1b97593f68b7",
              "IPY_MODEL_85321a204daf4b05964a21012a74fff1"
            ]
          }
        },
        "8e64d363bc7f4282994a3977e210733b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3134ebd7f7054d1a82670d300e33ef1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_00ba62ad89dc4816b5724c08a1bf4908",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2ee86c1d7b7342819f01e915b8918f74"
          }
        },
        "8bd427622f8e4c8cba2a1b97593f68b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_db8e581fc5fe419ab18c585ecc5ae514",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 109,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 109,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_15d530cbf08845cca4b9b632e04df536"
          }
        },
        "85321a204daf4b05964a21012a74fff1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_59f154abbe264f02a7a51bbd5f46997b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 109/109 [00:00&lt;00:00, 4.07kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_561e9063ac98439fa91450f2c74ed506"
          }
        },
        "00ba62ad89dc4816b5724c08a1bf4908": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2ee86c1d7b7342819f01e915b8918f74": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "db8e581fc5fe419ab18c585ecc5ae514": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "15d530cbf08845cca4b9b632e04df536": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "59f154abbe264f02a7a51bbd5f46997b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "561e9063ac98439fa91450f2c74ed506": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a49eb86aeb2347d4b67887d3b6e0a801": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_fd58458f4e3945a2a729c21d166383bf",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_998ccf5aaff54de49c8665ca2e7f6dc5",
              "IPY_MODEL_ba9facc8b9c64d81896f1ab4fb7cbb11",
              "IPY_MODEL_e202dd927ecb4bc5b8eac6e53efcf57e"
            ]
          }
        },
        "fd58458f4e3945a2a729c21d166383bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "998ccf5aaff54de49c8665ca2e7f6dc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8815ae252f7546d79015b17fe80ddbb6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_69144bc2a17e48f78a9f6648d6238ccf"
          }
        },
        "ba9facc8b9c64d81896f1ab4fb7cbb11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9ff35d95506c4fa2850c02ad578466f4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 2,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 2,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a982a9c126b844db889c2ca500f65e09"
          }
        },
        "e202dd927ecb4bc5b8eac6e53efcf57e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_062331f0fd6a4c33a8137d271f3bc60d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2.00/2.00 [00:00&lt;00:00, 81.1B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_15f62d1012ad48279c8a01db789cc6a2"
          }
        },
        "8815ae252f7546d79015b17fe80ddbb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "69144bc2a17e48f78a9f6648d6238ccf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9ff35d95506c4fa2850c02ad578466f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a982a9c126b844db889c2ca500f65e09": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "062331f0fd6a4c33a8137d271f3bc60d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "15f62d1012ad48279c8a01db789cc6a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "65e01966d0af4b7b97164761fb73054c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_70f948c92b1849c6997904ab358ceeb5",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a302f19fd0e64eb680aae1f5e4fc9d13",
              "IPY_MODEL_29c52b78367b442ea066dff0942dea9b",
              "IPY_MODEL_2ba2590f5ebd40c1908892ae2b5d5c65"
            ]
          }
        },
        "70f948c92b1849c6997904ab358ceeb5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a302f19fd0e64eb680aae1f5e4fc9d13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_863aba9be4d04c98819f31e1e6c9ab25",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0a088055497042619bfd4c27ea947902"
          }
        },
        "29c52b78367b442ea066dff0942dea9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3dcb342dec604fb7afd4aaee002785ce",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1051976,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1051976,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7f6a2502324648fcaabdd77d4730921e"
          }
        },
        "2ba2590f5ebd40c1908892ae2b5d5c65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_585ea296916f4459831a7b770536a9fb",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.00M/1.00M [00:00&lt;00:00, 8.13MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ee7c927b260a47c5b85ee4145d81193f"
          }
        },
        "863aba9be4d04c98819f31e1e6c9ab25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0a088055497042619bfd4c27ea947902": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3dcb342dec604fb7afd4aaee002785ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7f6a2502324648fcaabdd77d4730921e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "585ea296916f4459831a7b770536a9fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ee7c927b260a47c5b85ee4145d81193f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "03bc72b196444cfca519a0eb70070c76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d5ebee26b6be49868c87189ef0bcdbf5",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6a06b562f0f84d1f966d6f2527ab8ec9",
              "IPY_MODEL_55cc86553b90462eb60bce68d95db4b4",
              "IPY_MODEL_7343cf69f7f34ad1b5d0844239a78753"
            ]
          }
        },
        "d5ebee26b6be49868c87189ef0bcdbf5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6a06b562f0f84d1f966d6f2527ab8ec9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8b16172b5015401dbc5b2da9efba5252",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3ea221fb780c49c890aaec6a60a58e44"
          }
        },
        "55cc86553b90462eb60bce68d95db4b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2d1791c683b74b9e86d84a9495c319cf",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 731,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 731,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8ef65155e05b483683314cebac960310"
          }
        },
        "7343cf69f7f34ad1b5d0844239a78753": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_44c9325b1fe84ccab8a262ac7a40a025",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 731/731 [00:00&lt;00:00, 28.4kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cb7c71fa18194a5fb1c471e88140d173"
          }
        },
        "8b16172b5015401dbc5b2da9efba5252": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3ea221fb780c49c890aaec6a60a58e44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2d1791c683b74b9e86d84a9495c319cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8ef65155e05b483683314cebac960310": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "44c9325b1fe84ccab8a262ac7a40a025": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cb7c71fa18194a5fb1c471e88140d173": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "94d1a56f825942828294bd9b1d38b460": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8b02aa64a9634b23bf03a3326f9e1782",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1ff1efab8d9d492b947eb141544cd69d",
              "IPY_MODEL_fcad3236285144ed9cda734f501f1cb4",
              "IPY_MODEL_15dea6ffa0f34eb0af0c14486f9aecd9"
            ]
          }
        },
        "8b02aa64a9634b23bf03a3326f9e1782": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1ff1efab8d9d492b947eb141544cd69d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b848bff75d694b37a5e255a5ba336016",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3d51af14451a4791a07c2b051f2958fc"
          }
        },
        "fcad3236285144ed9cda734f501f1cb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0410f92dc0fe46e284535dedc5195171",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 4675508961,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 4675508961,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7cde95b9af5b47c691b35920f3c8afd2"
          }
        },
        "15dea6ffa0f34eb0af0c14486f9aecd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_245a303d935149ddbd7719e07ddd9d5f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 4.35G/4.35G [01:29&lt;00:00, 40.3MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9a357c346fe34634978a157c7ed13227"
          }
        },
        "b848bff75d694b37a5e255a5ba336016": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3d51af14451a4791a07c2b051f2958fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0410f92dc0fe46e284535dedc5195171": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7cde95b9af5b47c691b35920f3c8afd2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "245a303d935149ddbd7719e07ddd9d5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9a357c346fe34634978a157c7ed13227": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "835ffafa53714ab1aa650b8158df0bae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5e25f6813d9e48098c32707d462c2eae",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_54a53bf5743e4055921c203edc6d737d",
              "IPY_MODEL_4a56664acfb24bc1a3bb75a83d9386f3",
              "IPY_MODEL_6bcfb5608f834193abf15a1299f17ed2"
            ]
          }
        },
        "5e25f6813d9e48098c32707d462c2eae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "54a53bf5743e4055921c203edc6d737d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c54ce33210154cca8d336f854c54ae02",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Upload file pytorch_model.bin: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_987daf984f3a4a109e495a6089248bf3"
          }
        },
        "4a56664acfb24bc1a3bb75a83d9386f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_503ba1adcfb24b8ba4a57cec09dfe3a0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 4675513761,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 4675513761,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_12266d0755d444a397780bc1c324bb54"
          }
        },
        "6bcfb5608f834193abf15a1299f17ed2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f55e65b6f3ae49a0aa789b8607dc762e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 4.35G/4.35G [53:37&lt;00:00, 1.24MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_926916ca67274048bb911bd6c3bc0982"
          }
        },
        "c54ce33210154cca8d336f854c54ae02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "987daf984f3a4a109e495a6089248bf3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "503ba1adcfb24b8ba4a57cec09dfe3a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "12266d0755d444a397780bc1c324bb54": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f55e65b6f3ae49a0aa789b8607dc762e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "926916ca67274048bb911bd6c3bc0982": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/snoop2head/KoGPT-Joong-2/blob/main/conditional_gpt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Configuration & Data Setting"
      ],
      "metadata": {
        "id": "5gJh-h_JOR9Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7n_g5CxIBi3",
        "outputId": "59694c64-c8ab-4894-f450-faca27ff58d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Dec 24 19:58:46 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  A100-SXM4-40GB      Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P0    43W / 400W |      0MiB / 40536MiB |      0%      Default |\n",
            "|                               |                      |             Disabled |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install easydict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aE6sy8qMC-4E",
        "outputId": "cec03f50-b60a-4683-fea4-c79b0b39fdd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: easydict in /usr/local/lib/python3.7/dist-packages (1.9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eXhqUYDBkwJt",
        "outputId": "a535737d-ec8a-414c-a848-2b13654c769f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "shutil.copy(\"/content/drive/MyDrive/kogpt-joong-2-data/data/data_final_argmaxed.csv\", \"./\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 42
        },
        "id": "3Q4dH-3Pk55x",
        "outputId": "954d3681-df2c-49c3-dd39-8d7a601e7d9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'./data_final_argmaxed.csv'"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.flush_and_unmount()"
      ],
      "metadata": {
        "id": "VyZyBrHWlOal"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "djjTjrv2IsQE"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DATA_PATH = \"/content/drive/MyDrive/kogpt-joong-2-data/modeling\"\n",
        "# PSEUDO_LABELED_FILE_NAME = \"data_labeld_KoBERT_unhand_argmaxed_and_감성대화말뭉치.csv\"\n",
        "PSEUDO_LABELED_FILE_PATH = \"./data_final_argmaxed.csv\""
      ],
      "metadata": {
        "id": "sF-PpKohLmoT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "# pseudo_path = os.path.join(DATA_PATH, PSEUDO_LABELED_FILE_NAME)\n",
        "pseudo_path = PSEUDO_LABELED_FILE_PATH\n",
        "df_pseudo = pd.read_csv(pseudo_path, encoding=\"utf-8\")\n",
        "df_pseudo.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "id": "56q-RegCLmjj",
        "outputId": "ffb845c7-6917-4708-dacf-74ed0f2095b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-017b1406-f384-41ce-9bbe-da591f19250e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>text</th>\n",
              "      <th>공포</th>\n",
              "      <th>놀람</th>\n",
              "      <th>분노</th>\n",
              "      <th>슬픔</th>\n",
              "      <th>중립</th>\n",
              "      <th>행복</th>\n",
              "      <th>혐오</th>\n",
              "      <th>first_emotion</th>\n",
              "      <th>first_logit</th>\n",
              "      <th>second_logit</th>\n",
              "      <th>second_emotion</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>대화</td>\n",
              "      <td>드디어 샀다.</td>\n",
              "      <td>-1.976455</td>\n",
              "      <td>-0.497756</td>\n",
              "      <td>-1.301128</td>\n",
              "      <td>-1.327810</td>\n",
              "      <td>1.069673</td>\n",
              "      <td>5.177046</td>\n",
              "      <td>-1.353732</td>\n",
              "      <td>행복</td>\n",
              "      <td>5.177046</td>\n",
              "      <td>1.069673</td>\n",
              "      <td>중립</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>대화</td>\n",
              "      <td>뭐 하고 놀까.</td>\n",
              "      <td>1.932847</td>\n",
              "      <td>-2.145293</td>\n",
              "      <td>-1.495267</td>\n",
              "      <td>2.116858</td>\n",
              "      <td>2.249198</td>\n",
              "      <td>-1.559769</td>\n",
              "      <td>-0.994669</td>\n",
              "      <td>중립</td>\n",
              "      <td>2.249198</td>\n",
              "      <td>2.116858</td>\n",
              "      <td>슬픔</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>대화</td>\n",
              "      <td>오늘은 지각 안했어!.</td>\n",
              "      <td>-1.364891</td>\n",
              "      <td>-0.819980</td>\n",
              "      <td>-1.040110</td>\n",
              "      <td>-2.304478</td>\n",
              "      <td>1.620021</td>\n",
              "      <td>5.133489</td>\n",
              "      <td>-1.207578</td>\n",
              "      <td>행복</td>\n",
              "      <td>5.133489</td>\n",
              "      <td>1.620021</td>\n",
              "      <td>중립</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>대화</td>\n",
              "      <td>오늘 점심 제육볶음 이래!.</td>\n",
              "      <td>-1.533068</td>\n",
              "      <td>-0.162358</td>\n",
              "      <td>-0.926851</td>\n",
              "      <td>-2.654852</td>\n",
              "      <td>2.069342</td>\n",
              "      <td>4.444376</td>\n",
              "      <td>-1.225262</td>\n",
              "      <td>행복</td>\n",
              "      <td>4.444376</td>\n",
              "      <td>2.069342</td>\n",
              "      <td>중립</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>대화</td>\n",
              "      <td>나 먼저 갈게.</td>\n",
              "      <td>-0.676803</td>\n",
              "      <td>-1.909779</td>\n",
              "      <td>-2.075403</td>\n",
              "      <td>0.887898</td>\n",
              "      <td>1.514351</td>\n",
              "      <td>4.160100</td>\n",
              "      <td>-2.037050</td>\n",
              "      <td>행복</td>\n",
              "      <td>4.160100</td>\n",
              "      <td>1.514351</td>\n",
              "      <td>중립</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-017b1406-f384-41ce-9bbe-da591f19250e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-017b1406-f384-41ce-9bbe-da591f19250e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-017b1406-f384-41ce-9bbe-da591f19250e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "  type             text        공포  ...  first_logit  second_logit  second_emotion\n",
              "0   대화          드디어 샀다. -1.976455  ...     5.177046      1.069673              중립\n",
              "1   대화         뭐 하고 놀까.  1.932847  ...     2.249198      2.116858              슬픔\n",
              "2   대화     오늘은 지각 안했어!. -1.364891  ...     5.133489      1.620021              중립\n",
              "3   대화  오늘 점심 제육볶음 이래!. -1.533068  ...     4.444376      2.069342              중립\n",
              "4   대화         나 먼저 갈게. -0.676803  ...     4.160100      1.514351              중립\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pseudo.tail()"
      ],
      "metadata": {
        "id": "aGwgGuS0LmeC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c2ad7677-c338-42ae-96a2-f9dea147a555"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-43134a58-7ae9-43a6-b2b5-8696a970b54f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>text</th>\n",
              "      <th>공포</th>\n",
              "      <th>놀람</th>\n",
              "      <th>분노</th>\n",
              "      <th>슬픔</th>\n",
              "      <th>중립</th>\n",
              "      <th>행복</th>\n",
              "      <th>혐오</th>\n",
              "      <th>first_emotion</th>\n",
              "      <th>first_logit</th>\n",
              "      <th>second_logit</th>\n",
              "      <th>second_emotion</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>494091</th>\n",
              "      <td>노래 가사</td>\n",
              "      <td>눈물은 뚝 눈물은 뚝 얼싸 안고 춤을 춰보자 춘향아 춘향아 눈물을 거둬라</td>\n",
              "      <td>-1.791054</td>\n",
              "      <td>-2.507724</td>\n",
              "      <td>-0.895269</td>\n",
              "      <td>0.827443</td>\n",
              "      <td>3.551021</td>\n",
              "      <td>1.050611</td>\n",
              "      <td>-0.640308</td>\n",
              "      <td>중립</td>\n",
              "      <td>3.551021</td>\n",
              "      <td>1.050611</td>\n",
              "      <td>행복</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>494092</th>\n",
              "      <td>노래 가사</td>\n",
              "      <td>어차피 다 지난 일인걸 더 이상 무슨 말이 필요해 서둘지 말고 한걸음씩 즐겨봐</td>\n",
              "      <td>-2.078648</td>\n",
              "      <td>-1.968988</td>\n",
              "      <td>-2.018869</td>\n",
              "      <td>0.097698</td>\n",
              "      <td>3.121234</td>\n",
              "      <td>3.633747</td>\n",
              "      <td>-1.375754</td>\n",
              "      <td>행복</td>\n",
              "      <td>3.633747</td>\n",
              "      <td>3.121234</td>\n",
              "      <td>중립</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>494093</th>\n",
              "      <td>노래 가사</td>\n",
              "      <td>참 미안해 이제 그만 아프지 마 제발 힘들었지 떠나지마 참 미안해 이러지마</td>\n",
              "      <td>-0.457692</td>\n",
              "      <td>-0.860459</td>\n",
              "      <td>-0.770534</td>\n",
              "      <td>5.504443</td>\n",
              "      <td>-1.656590</td>\n",
              "      <td>-0.837802</td>\n",
              "      <td>-1.208101</td>\n",
              "      <td>슬픔</td>\n",
              "      <td>5.504443</td>\n",
              "      <td>-0.457692</td>\n",
              "      <td>공포</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>494094</th>\n",
              "      <td>노래 가사</td>\n",
              "      <td>내 못난 마음 꿈에서는 다 용서해 주세요</td>\n",
              "      <td>-0.706598</td>\n",
              "      <td>-2.820624</td>\n",
              "      <td>-1.454884</td>\n",
              "      <td>4.223856</td>\n",
              "      <td>0.895535</td>\n",
              "      <td>1.043546</td>\n",
              "      <td>-1.225848</td>\n",
              "      <td>슬픔</td>\n",
              "      <td>4.223856</td>\n",
              "      <td>1.043546</td>\n",
              "      <td>행복</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>494095</th>\n",
              "      <td>노래 가사</td>\n",
              "      <td>이 날이 오기 전에 난 어떻게 품는 줄 몰랐죠</td>\n",
              "      <td>1.442261</td>\n",
              "      <td>1.019177</td>\n",
              "      <td>-2.571514</td>\n",
              "      <td>3.298930</td>\n",
              "      <td>0.045752</td>\n",
              "      <td>0.175383</td>\n",
              "      <td>-3.429953</td>\n",
              "      <td>슬픔</td>\n",
              "      <td>3.298930</td>\n",
              "      <td>1.442261</td>\n",
              "      <td>공포</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-43134a58-7ae9-43a6-b2b5-8696a970b54f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-43134a58-7ae9-43a6-b2b5-8696a970b54f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-43134a58-7ae9-43a6-b2b5-8696a970b54f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "         type  ... second_emotion\n",
              "494091  노래 가사  ...             행복\n",
              "494092  노래 가사  ...             중립\n",
              "494093  노래 가사  ...             공포\n",
              "494094  노래 가사  ...             행복\n",
              "494095  노래 가사  ...             공포\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_pseudo.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88ZFT4u7yhPi",
        "outputId": "eb60c474-bbf4-4f13-94ba-e5b2c4d75000"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(494096, 13)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pseudo[\"first_logit\"] = df_pseudo[\"first_logit\"].round(1)\n",
        "df_pseudo[\"second_logit\"] = df_pseudo[\"second_logit\"].round(1)"
      ],
      "metadata": {
        "id": "Zt9YVMTNF3A3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pseudo[\"train_text\"] = \\\n",
        "  df_pseudo[\"first_logit\"].astype(str) + \"만큼 \" + df_pseudo[\"first_emotion\"].astype(str) + \"감정인 문장이다. \" +  \\\n",
        "  df_pseudo[\"second_logit\"].astype(str) + \"만큼 \" + df_pseudo[\"second_emotion\"].astype(str) + \"감정인 문장이다. \" +  \\\n",
        "  df_pseudo[\"text\"].astype(str)\n",
        "df_pseudo.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 652
        },
        "id": "BliDjRRgDXxl",
        "outputId": "cd24f536-5132-4290-8256-ae0810018b8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-6450fa94-598e-486b-bffb-1afc093e8087\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>text</th>\n",
              "      <th>공포</th>\n",
              "      <th>놀람</th>\n",
              "      <th>분노</th>\n",
              "      <th>슬픔</th>\n",
              "      <th>중립</th>\n",
              "      <th>행복</th>\n",
              "      <th>혐오</th>\n",
              "      <th>first_emotion</th>\n",
              "      <th>first_logit</th>\n",
              "      <th>second_logit</th>\n",
              "      <th>second_emotion</th>\n",
              "      <th>train_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>대화</td>\n",
              "      <td>드디어 샀다.</td>\n",
              "      <td>-1.976455</td>\n",
              "      <td>-0.497756</td>\n",
              "      <td>-1.301128</td>\n",
              "      <td>-1.327810</td>\n",
              "      <td>1.069673</td>\n",
              "      <td>5.177046</td>\n",
              "      <td>-1.353732</td>\n",
              "      <td>행복</td>\n",
              "      <td>5.2</td>\n",
              "      <td>1.1</td>\n",
              "      <td>중립</td>\n",
              "      <td>5.2만큼 행복감정인 문장이다. 1.1만큼 중립감정인 문장이다. 드디어 샀다.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>대화</td>\n",
              "      <td>뭐 하고 놀까.</td>\n",
              "      <td>1.932847</td>\n",
              "      <td>-2.145293</td>\n",
              "      <td>-1.495267</td>\n",
              "      <td>2.116858</td>\n",
              "      <td>2.249198</td>\n",
              "      <td>-1.559769</td>\n",
              "      <td>-0.994669</td>\n",
              "      <td>중립</td>\n",
              "      <td>2.2</td>\n",
              "      <td>2.1</td>\n",
              "      <td>슬픔</td>\n",
              "      <td>2.2만큼 중립감정인 문장이다. 2.1만큼 슬픔감정인 문장이다. 뭐 하고 놀까.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>대화</td>\n",
              "      <td>오늘은 지각 안했어!.</td>\n",
              "      <td>-1.364891</td>\n",
              "      <td>-0.819980</td>\n",
              "      <td>-1.040110</td>\n",
              "      <td>-2.304478</td>\n",
              "      <td>1.620021</td>\n",
              "      <td>5.133489</td>\n",
              "      <td>-1.207578</td>\n",
              "      <td>행복</td>\n",
              "      <td>5.1</td>\n",
              "      <td>1.6</td>\n",
              "      <td>중립</td>\n",
              "      <td>5.1만큼 행복감정인 문장이다. 1.6만큼 중립감정인 문장이다. 오늘은 지각 안했어!.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>대화</td>\n",
              "      <td>오늘 점심 제육볶음 이래!.</td>\n",
              "      <td>-1.533068</td>\n",
              "      <td>-0.162358</td>\n",
              "      <td>-0.926851</td>\n",
              "      <td>-2.654852</td>\n",
              "      <td>2.069342</td>\n",
              "      <td>4.444376</td>\n",
              "      <td>-1.225262</td>\n",
              "      <td>행복</td>\n",
              "      <td>4.4</td>\n",
              "      <td>2.1</td>\n",
              "      <td>중립</td>\n",
              "      <td>4.4만큼 행복감정인 문장이다. 2.1만큼 중립감정인 문장이다. 오늘 점심 제육볶음...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>대화</td>\n",
              "      <td>나 먼저 갈게.</td>\n",
              "      <td>-0.676803</td>\n",
              "      <td>-1.909779</td>\n",
              "      <td>-2.075403</td>\n",
              "      <td>0.887898</td>\n",
              "      <td>1.514351</td>\n",
              "      <td>4.160100</td>\n",
              "      <td>-2.037050</td>\n",
              "      <td>행복</td>\n",
              "      <td>4.2</td>\n",
              "      <td>1.5</td>\n",
              "      <td>중립</td>\n",
              "      <td>4.2만큼 행복감정인 문장이다. 1.5만큼 중립감정인 문장이다. 나 먼저 갈게.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6450fa94-598e-486b-bffb-1afc093e8087')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6450fa94-598e-486b-bffb-1afc093e8087 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6450fa94-598e-486b-bffb-1afc093e8087');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "  type  ...                                         train_text\n",
              "0   대화  ...        5.2만큼 행복감정인 문장이다. 1.1만큼 중립감정인 문장이다. 드디어 샀다.\n",
              "1   대화  ...       2.2만큼 중립감정인 문장이다. 2.1만큼 슬픔감정인 문장이다. 뭐 하고 놀까.\n",
              "2   대화  ...   5.1만큼 행복감정인 문장이다. 1.6만큼 중립감정인 문장이다. 오늘은 지각 안했어!.\n",
              "3   대화  ...  4.4만큼 행복감정인 문장이다. 2.1만큼 중립감정인 문장이다. 오늘 점심 제육볶음...\n",
              "4   대화  ...       4.2만큼 행복감정인 문장이다. 1.5만큼 중립감정인 문장이다. 나 먼저 갈게.\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pseudo.tail()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yzy2X9aeETiE",
        "outputId": "8df2ee7e-4feb-4990-fd83-911dab44112a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-a1483382-1929-416d-ba3c-16910e7bf5ea\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>text</th>\n",
              "      <th>공포</th>\n",
              "      <th>놀람</th>\n",
              "      <th>분노</th>\n",
              "      <th>슬픔</th>\n",
              "      <th>중립</th>\n",
              "      <th>행복</th>\n",
              "      <th>혐오</th>\n",
              "      <th>first_emotion</th>\n",
              "      <th>first_logit</th>\n",
              "      <th>second_logit</th>\n",
              "      <th>second_emotion</th>\n",
              "      <th>train_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>494091</th>\n",
              "      <td>노래 가사</td>\n",
              "      <td>눈물은 뚝 눈물은 뚝 얼싸 안고 춤을 춰보자 춘향아 춘향아 눈물을 거둬라</td>\n",
              "      <td>-1.791054</td>\n",
              "      <td>-2.507724</td>\n",
              "      <td>-0.895269</td>\n",
              "      <td>0.827443</td>\n",
              "      <td>3.551021</td>\n",
              "      <td>1.050611</td>\n",
              "      <td>-0.640308</td>\n",
              "      <td>중립</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.1</td>\n",
              "      <td>행복</td>\n",
              "      <td>3.6만큼 중립감정인 문장이다. 1.1만큼 행복감정인 문장이다. 눈물은 뚝 눈물은 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>494092</th>\n",
              "      <td>노래 가사</td>\n",
              "      <td>어차피 다 지난 일인걸 더 이상 무슨 말이 필요해 서둘지 말고 한걸음씩 즐겨봐</td>\n",
              "      <td>-2.078648</td>\n",
              "      <td>-1.968988</td>\n",
              "      <td>-2.018869</td>\n",
              "      <td>0.097698</td>\n",
              "      <td>3.121234</td>\n",
              "      <td>3.633747</td>\n",
              "      <td>-1.375754</td>\n",
              "      <td>행복</td>\n",
              "      <td>3.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>중립</td>\n",
              "      <td>3.6만큼 행복감정인 문장이다. 3.1만큼 중립감정인 문장이다. 어차피 다 지난 일...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>494093</th>\n",
              "      <td>노래 가사</td>\n",
              "      <td>참 미안해 이제 그만 아프지 마 제발 힘들었지 떠나지마 참 미안해 이러지마</td>\n",
              "      <td>-0.457692</td>\n",
              "      <td>-0.860459</td>\n",
              "      <td>-0.770534</td>\n",
              "      <td>5.504443</td>\n",
              "      <td>-1.656590</td>\n",
              "      <td>-0.837802</td>\n",
              "      <td>-1.208101</td>\n",
              "      <td>슬픔</td>\n",
              "      <td>5.5</td>\n",
              "      <td>-0.5</td>\n",
              "      <td>공포</td>\n",
              "      <td>5.5만큼 슬픔감정인 문장이다. -0.5만큼 공포감정인 문장이다. 참 미안해 이제 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>494094</th>\n",
              "      <td>노래 가사</td>\n",
              "      <td>내 못난 마음 꿈에서는 다 용서해 주세요</td>\n",
              "      <td>-0.706598</td>\n",
              "      <td>-2.820624</td>\n",
              "      <td>-1.454884</td>\n",
              "      <td>4.223856</td>\n",
              "      <td>0.895535</td>\n",
              "      <td>1.043546</td>\n",
              "      <td>-1.225848</td>\n",
              "      <td>슬픔</td>\n",
              "      <td>4.2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>행복</td>\n",
              "      <td>4.2만큼 슬픔감정인 문장이다. 1.0만큼 행복감정인 문장이다. 내 못난 마음 꿈에...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>494095</th>\n",
              "      <td>노래 가사</td>\n",
              "      <td>이 날이 오기 전에 난 어떻게 품는 줄 몰랐죠</td>\n",
              "      <td>1.442261</td>\n",
              "      <td>1.019177</td>\n",
              "      <td>-2.571514</td>\n",
              "      <td>3.298930</td>\n",
              "      <td>0.045752</td>\n",
              "      <td>0.175383</td>\n",
              "      <td>-3.429953</td>\n",
              "      <td>슬픔</td>\n",
              "      <td>3.3</td>\n",
              "      <td>1.4</td>\n",
              "      <td>공포</td>\n",
              "      <td>3.3만큼 슬픔감정인 문장이다. 1.4만큼 공포감정인 문장이다. 이 날이 오기 전에...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a1483382-1929-416d-ba3c-16910e7bf5ea')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a1483382-1929-416d-ba3c-16910e7bf5ea button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a1483382-1929-416d-ba3c-16910e7bf5ea');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "         type  ...                                         train_text\n",
              "494091  노래 가사  ...  3.6만큼 중립감정인 문장이다. 1.1만큼 행복감정인 문장이다. 눈물은 뚝 눈물은 ...\n",
              "494092  노래 가사  ...  3.6만큼 행복감정인 문장이다. 3.1만큼 중립감정인 문장이다. 어차피 다 지난 일...\n",
              "494093  노래 가사  ...  5.5만큼 슬픔감정인 문장이다. -0.5만큼 공포감정인 문장이다. 참 미안해 이제 ...\n",
              "494094  노래 가사  ...  4.2만큼 슬픔감정인 문장이다. 1.0만큼 행복감정인 문장이다. 내 못난 마음 꿈에...\n",
              "494095  노래 가사  ...  3.3만큼 슬픔감정인 문장이다. 1.4만큼 공포감정인 문장이다. 이 날이 오기 전에...\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pseudo[\"train_text\"] = df_pseudo[\"train_text\"].str.replace(\"nan만큼 nan감정인 문장이다.\", \"\")\n",
        "df_pseudo.tail()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-7z_oooVETgF",
        "outputId": "7d473c65-cc8c-4676-85ae-0dd54b765785"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-0a90eb14-e857-4fc4-b9ed-fd8b4a15b98b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>text</th>\n",
              "      <th>공포</th>\n",
              "      <th>놀람</th>\n",
              "      <th>분노</th>\n",
              "      <th>슬픔</th>\n",
              "      <th>중립</th>\n",
              "      <th>행복</th>\n",
              "      <th>혐오</th>\n",
              "      <th>first_emotion</th>\n",
              "      <th>first_logit</th>\n",
              "      <th>second_logit</th>\n",
              "      <th>second_emotion</th>\n",
              "      <th>train_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>494091</th>\n",
              "      <td>노래 가사</td>\n",
              "      <td>눈물은 뚝 눈물은 뚝 얼싸 안고 춤을 춰보자 춘향아 춘향아 눈물을 거둬라</td>\n",
              "      <td>-1.791054</td>\n",
              "      <td>-2.507724</td>\n",
              "      <td>-0.895269</td>\n",
              "      <td>0.827443</td>\n",
              "      <td>3.551021</td>\n",
              "      <td>1.050611</td>\n",
              "      <td>-0.640308</td>\n",
              "      <td>중립</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.1</td>\n",
              "      <td>행복</td>\n",
              "      <td>3.6만큼 중립감정인 문장이다. 1.1만큼 행복감정인 문장이다. 눈물은 뚝 눈물은 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>494092</th>\n",
              "      <td>노래 가사</td>\n",
              "      <td>어차피 다 지난 일인걸 더 이상 무슨 말이 필요해 서둘지 말고 한걸음씩 즐겨봐</td>\n",
              "      <td>-2.078648</td>\n",
              "      <td>-1.968988</td>\n",
              "      <td>-2.018869</td>\n",
              "      <td>0.097698</td>\n",
              "      <td>3.121234</td>\n",
              "      <td>3.633747</td>\n",
              "      <td>-1.375754</td>\n",
              "      <td>행복</td>\n",
              "      <td>3.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>중립</td>\n",
              "      <td>3.6만큼 행복감정인 문장이다. 3.1만큼 중립감정인 문장이다. 어차피 다 지난 일...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>494093</th>\n",
              "      <td>노래 가사</td>\n",
              "      <td>참 미안해 이제 그만 아프지 마 제발 힘들었지 떠나지마 참 미안해 이러지마</td>\n",
              "      <td>-0.457692</td>\n",
              "      <td>-0.860459</td>\n",
              "      <td>-0.770534</td>\n",
              "      <td>5.504443</td>\n",
              "      <td>-1.656590</td>\n",
              "      <td>-0.837802</td>\n",
              "      <td>-1.208101</td>\n",
              "      <td>슬픔</td>\n",
              "      <td>5.5</td>\n",
              "      <td>-0.5</td>\n",
              "      <td>공포</td>\n",
              "      <td>5.5만큼 슬픔감정인 문장이다. -0.5만큼 공포감정인 문장이다. 참 미안해 이제 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>494094</th>\n",
              "      <td>노래 가사</td>\n",
              "      <td>내 못난 마음 꿈에서는 다 용서해 주세요</td>\n",
              "      <td>-0.706598</td>\n",
              "      <td>-2.820624</td>\n",
              "      <td>-1.454884</td>\n",
              "      <td>4.223856</td>\n",
              "      <td>0.895535</td>\n",
              "      <td>1.043546</td>\n",
              "      <td>-1.225848</td>\n",
              "      <td>슬픔</td>\n",
              "      <td>4.2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>행복</td>\n",
              "      <td>4.2만큼 슬픔감정인 문장이다. 1.0만큼 행복감정인 문장이다. 내 못난 마음 꿈에...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>494095</th>\n",
              "      <td>노래 가사</td>\n",
              "      <td>이 날이 오기 전에 난 어떻게 품는 줄 몰랐죠</td>\n",
              "      <td>1.442261</td>\n",
              "      <td>1.019177</td>\n",
              "      <td>-2.571514</td>\n",
              "      <td>3.298930</td>\n",
              "      <td>0.045752</td>\n",
              "      <td>0.175383</td>\n",
              "      <td>-3.429953</td>\n",
              "      <td>슬픔</td>\n",
              "      <td>3.3</td>\n",
              "      <td>1.4</td>\n",
              "      <td>공포</td>\n",
              "      <td>3.3만큼 슬픔감정인 문장이다. 1.4만큼 공포감정인 문장이다. 이 날이 오기 전에...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0a90eb14-e857-4fc4-b9ed-fd8b4a15b98b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0a90eb14-e857-4fc4-b9ed-fd8b4a15b98b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0a90eb14-e857-4fc4-b9ed-fd8b4a15b98b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "         type  ...                                         train_text\n",
              "494091  노래 가사  ...  3.6만큼 중립감정인 문장이다. 1.1만큼 행복감정인 문장이다. 눈물은 뚝 눈물은 ...\n",
              "494092  노래 가사  ...  3.6만큼 행복감정인 문장이다. 3.1만큼 중립감정인 문장이다. 어차피 다 지난 일...\n",
              "494093  노래 가사  ...  5.5만큼 슬픔감정인 문장이다. -0.5만큼 공포감정인 문장이다. 참 미안해 이제 ...\n",
              "494094  노래 가사  ...  4.2만큼 슬픔감정인 문장이다. 1.0만큼 행복감정인 문장이다. 내 못난 마음 꿈에...\n",
              "494095  노래 가사  ...  3.3만큼 슬픔감정인 문장이다. 1.4만큼 공포감정인 문장이다. 이 날이 오기 전에...\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load and Create Conditions for Dataset "
      ],
      "metadata": {
        "id": "U-32cxdBDL1x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from datetime import datetime\n",
        "from easydict import EasyDict\n",
        "\n",
        "# Initialize configuration\n",
        "CFG = EasyDict()\n",
        "\n",
        "# Dataset Config as constants\n",
        "ROOT_PATH = os.path.abspath(\".\")\n",
        "CFG.DEBUG = False\n",
        "CFG.num_workers = 4\n",
        "CFG.train_batch_size = 42\n",
        "\n",
        "# Train configuration\n",
        "CFG.user_name = \"snoop2head\"\n",
        "today = datetime.now().strftime(\"%m%d_%H:%M\")\n",
        "CFG.file_base_name = f\"{CFG.user_name}_{today}\"\n",
        "CFG.model_dir = \"skt/ko-gpt-trinity-1.2B-v0.5\" # designate the model's name registered on huggingface: https://huggingface.co/skt/ko-gpt-trinity-1.2B-v0.5\n",
        "CFG.max_token_length = 42\n",
        "CFG.learning_rate = 5e-5\n",
        "CFG.weight_decay = 5e-3 # https://paperswithcode.com/method/weight-decay\n",
        "\n",
        "# training steps configurations\n",
        "CFG.save_steps = 5000\n",
        "CFG.early_stopping_patience = 5\n",
        "CFG.warmup_steps = 500\n",
        "CFG.logging_steps = 5000\n",
        "evaluation_strategy = \"steps\"\n",
        "CFG.evaluation_steps = 5000\n",
        "\n",
        "# Directory configuration\n",
        "CFG.result_dir = os.path.join(ROOT_PATH, \"results\")\n",
        "CFG.saved_model_dir = os.path.join(ROOT_PATH, \"best_models\")\n",
        "CFG.logging_dir = os.path.join(ROOT_PATH, \"logs\")\n",
        "CFG.baseline_dir = os.path.join(ROOT_PATH, 'baseline-code')\n",
        "\n",
        "print(CFG)"
      ],
      "metadata": {
        "id": "pW-At8KozjWS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b144389-4f17-4cd0-dd08-c2467547f3ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'DEBUG': False, 'num_workers': 4, 'train_batch_size': 42, 'user_name': 'snoop2head', 'file_base_name': 'snoop2head_1224_20:00', 'model_dir': 'skt/ko-gpt-trinity-1.2B-v0.5', 'max_token_length': 42, 'learning_rate': 5e-05, 'weight_decay': 0.005, 'save_steps': 5000, 'early_stopping_patience': 5, 'warmup_steps': 500, 'logging_steps': 5000, 'evaluation_steps': 5000, 'result_dir': '/content/results', 'saved_model_dir': '/content/best_models', 'logging_dir': '/content/logs', 'baseline_dir': '/content/baseline-code'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.mkdir(CFG.result_dir)\n",
        "os.mkdir(CFG.saved_model_dir)\n",
        "os.mkdir(CFG.logging_dir)\n",
        "os.mkdir(CFG.baseline_dir)"
      ],
      "metadata": {
        "id": "4CcA99enbXJY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
        "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
        "\n",
        "def seed_everything(seed) :\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed) # if use multi-GPU\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "seed_everything(42)"
      ],
      "metadata": {
        "id": "OTnBVQ_9DDd9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "list_train_text = list(df_pseudo[\"train_text\"])\n",
        "random.choices(list_train_text, k = 100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "431gvp9zDIhZ",
        "outputId": "d34328b2-5805-4fcf-d3c2-1169a0eff56e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['4.1만큼 중립감정인 문장이다. 1.4만큼 행복감정인 문장이다. 남편과 나와의 인연을 생각하면 1950년대 중반쯤 고향풍경이 떠오른다',\n",
              " '5.1만큼 슬픔감정인 문장이다. 0.1만큼 중립감정인 문장이다. 모든 헤어짐에는 이유가 있다. 그 사람은 그 이유만으로 이미 죽은 사람이고',\n",
              " '4.6만큼 슬픔감정인 문장이다. 0.8만큼 행복감정인 문장이다. 그런 우리를 안타깝게, 그리고 서글프게 바라보시던 선생님은 결국 눈물을 보이고야 마셨다',\n",
              " '4.1만큼 중립감정인 문장이다. 0.5만큼 혐오감정인 문장이다. 실수란 것은 따지고 보면 성격과 관련이 깊다',\n",
              " '4.5만큼 슬픔감정인 문장이다. 1.6만큼 공포감정인 문장이다. 그래서 행복을 더 이상 깨닫지 못하는 것은 아닐는지',\n",
              " '3.6만큼 행복감정인 문장이다. 2.1만큼 놀람감정인 문장이다. 자야! 자야! 와 우노? 눈꺼풀 속에서 빛이 환했다',\n",
              " '3.6만큼 중립감정인 문장이다. 2.5만큼 혐오감정인 문장이다. 내한 가수가 국내 음방에서 1위해도 이렇게는 안할듯 아 너네도 그래미랑 빌보드 좋아하지',\n",
              " '4.1만큼 분노감정인 문장이다. 2.7만큼 슬픔감정인 문장이다. 아무리 생각해도 내 잘못이 아닌데 맞은 것에 대해 화가 나. 내 잘못이 아닌데도 왜 맞아야 하는지 모르겠어. 너무 답답해. 그 친구에게 가서 왜 때렸는지 물어봐야겠어. ',\n",
              " '5.0만큼 행복감정인 문장이다. 2.0만큼 중립감정인 문장이다. 내년에 또 만나요, 안녕!회장이 불편함 없이 대전터미널까지 택시를 대절해 줬다',\n",
              " '4.3만큼 분노감정인 문장이다. 1.5만큼 슬픔감정인 문장이다. 남자는 나이가 들수록 어려진다더니 남편은 내가 챙겨주지 않으면 아무것도 할 수 없어서 짜증 나. 남편을 챙겨주는 것이 어렵지 않지만 혼자서 아무것도 하지 않는 건 짜증 나. 너무 화가 나. 남편이 혼자서 할 수 있도록 해결책을 찾아봐야겠어. ',\n",
              " '3.5만큼 중립감정인 문장이다. 1.8만큼 행복감정인 문장이다. 사람의 본성에는 소멸되지 않은 신성이 남아있다고 하니, 나무아래에 서면 신성과의 조우가 이뤄지는 가보다',\n",
              " '4.5만큼 행복감정인 문장이다. 2.7만큼 중립감정인 문장이다. 넓은 마당과 집 주위를 훨훨 나는 참새들에게 봄의 왈츠라도 틀어주고 싶다',\n",
              " '4.4만큼 중립감정인 문장이다. 0.3만큼 공포감정인 문장이다. 그리고 불가능한걸 가능으로 바꾸려면 먼저 그 능력을 키워야한다.',\n",
              " '3.1만큼 중립감정인 문장이다. 2.9만큼 행복감정인 문장이다. 아직 귀가하지 않은 작은 아이를 기다리며 창밖을 내다본다',\n",
              " '4.1만큼 중립감정인 문장이다. 0.8만큼 행복감정인 문장이다. 인과 연이 만나서 사랑으로 열매 맺은 생멸의 순환이다',\n",
              " '4.1만큼 행복감정인 문장이다. 2.1만큼 중립감정인 문장이다. 박물관 내부에는 갖가지 사진으로 그들의 발전 모습을 전시해 놓았고, 많은 현지 사람들로 북적인다',\n",
              " '2.5만큼 중립감정인 문장이다. 1.5만큼 공포감정인 문장이다. 그리고 여인의 치맛자락이 스치는 소리와, 조용히 미닫이가 열리는 소리와, 내 이름을 부르는 소리',\n",
              " '4.8만큼 중립감정인 문장이다. 0.1만큼 혐오감정인 문장이다. 이것이 무릇 모든 젖의 자연일 것이다',\n",
              " '1.9만큼 슬픔감정인 문장이다. 1.6만큼 혐오감정인 문장이다. 아무런 의미도 없어보인다 아무것도 안중요한 것도',\n",
              " '4.7만큼 중립감정인 문장이다. 0.2만큼 놀람감정인 문장이다. 내가 없는 사이에 에타에 사람이 많이 몰리겠지. 에타에 사람이 많이 몰리겠지?',\n",
              " '4.2만큼 행복감정인 문장이다. 2.1만큼 슬픔감정인 문장이다. 오 그대에게 나는 너와 나의 사랑을 닮아 가 네게',\n",
              " '4.3만큼 중립감정인 문장이다. 1.2만큼 행복감정인 문장이다. 중학교 때던가 어느 해 여름 원두막을 지키고 있을 때다',\n",
              " '1.3만큼 놀람감정인 문장이다. 1.3만큼 공포감정인 문장이다. 8시 40분까지 도착해야 하고 9시에 차를 타기로 되어있었는데 몇 분 늦었다',\n",
              " '2.7만큼 중립감정인 문장이다. 2.7만큼 공포감정인 문장이다.  점심에 탄수화물을 더 줄여야 하나요?',\n",
              " '4.4만큼 행복감정인 문장이다. 2.9만큼 중립감정인 문장이다. 백만뷰 어렵지 않아요 그냥 채연이처럼 추면 간단함 훗!',\n",
              " '4.3만큼 중립감정인 문장이다. -0.1만큼 공포감정인 문장이다. 글을 읽기 시작하자 마자,나는 머릿속으로 이 글에 대한 반박을 하기 시작했다',\n",
              " '5.3만큼 슬픔감정인 문장이다. 1.1만큼 공포감정인 문장이다. 내 잘못이 아니라는 말을 회사에서는 아무도 믿어주지 않아서 슬퍼. 회사 사람들이 나를 믿지 못하니까 매일 마주치는 것도 두려워. 부장님께 면담을 신청해서 왜 내 잘못이 아닌지 다시 한번 설명 드려야겠어. ',\n",
              " '4.9만큼 분노감정인 문장이다. 1.0만큼 공포감정인 문장이다. 사이가 안 좋았던 친구가 좋은 직장의 면접을 앞두고 있대. 합격 못했으면 좋겠어. 나를 무시하던 그 친구가 나보다 좋은 직장에 들어가는 건 싫어. 지금 준비하고 있던 자격증 시험에 반드시 합격해서 목표로 하고 있는 직장에 지원해야겠어. ',\n",
              " '3.8만큼 중립감정인 문장이다. 1.7만큼 행복감정인 문장이다. 그저 상대의 이야기를 잘 들어주는 것으로도 심리적인 부자는 얼마든지 가능하다.',\n",
              " '2.4만큼 중립감정인 문장이다. 1.9만큼 놀람감정인 문장이다. 외벽에 설치된 안내문이 아니었다면 정체를 알 수 없었을 것이다',\n",
              " '2.9만큼 혐오감정인 문장이다. 2.3만큼 슬픔감정인 문장이다. 참아내는 하루가 길다. 자괴감 오지네 ᄉᄇ',\n",
              " '2.5만큼 중립감정인 문장이다. 0.9만큼 분노감정인 문장이다. 그리하여 바닥에 깔린 눅눅한 심기를 걷어내고 싶었을지도 모른다',\n",
              " '4.3만큼 행복감정인 문장이다. 2.5만큼 중립감정인 문장이다. 버터와 잼, 커다란 통밀빵 2개, 따뜻한 커피와 음료가 나왔다',\n",
              " '2.7만큼 놀람감정인 문장이다. 2.2만큼 행복감정인 문장이다. ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ그때 실력 원탑이 누구였는지 생각해보면 ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ',\n",
              " '3.0만큼 혐오감정인 문장이다. 2.3만큼 분노감정인 문장이다. 이밖에도 재수 털리는 한 내숭스러운 소녀의 실상을 까발리자면 한도 끝도 없다',\n",
              " '4.2만큼 슬픔감정인 문장이다. 1.2만큼 공포감정인 문장이다. 거미줄처럼 얽히고설킨 골목길을 빠져나오는 것도 쉽지가 않았었다',\n",
              " '3.0만큼 중립감정인 문장이다. 2.6만큼 슬픔감정인 문장이다. 잘못을 뉘우치고 진심으로 사과했다면 그걸로 됐어 알아주지 않아도 괜찮아 노력 많이 했으면 됐어',\n",
              " '3.0만큼 혐오감정인 문장이다. 2.7만큼 분노감정인 문장이다. 먹는 만큼 살이 불어난다고 그 좋은 아이스크림을 먹지 않는 사람이 있다',\n",
              " '2.8만큼 중립감정인 문장이다. 2.2만큼 슬픔감정인 문장이다. 사랑이라는 이유로 하얗게 새운 많은 밤들',\n",
              " '2.9만큼 슬픔감정인 문장이다. 1.4만큼 중립감정인 문장이다. 구실이 생겼으니 이제 해숙이를 쫓아내는 일만 남았다고 동생을 위로했다',\n",
              " '5.2만큼 슬픔감정인 문장이다. 0.2만큼 분노감정인 문장이다. 등 따시고 배부른 소리랄지 모르겠지만 내 인생의 마지막 돈은 이렇게 스러지고 말았다',\n",
              " '6.0만큼 행복감정인 문장이다. -0.2만큼 공포감정인 문장이다. 오늘 한국어 교환할 외국 친구 만나기로 했어. 이번 기회에 외국 친구도 만들어 보고 싶어. 그 친구들도 나를 좋아했으면 좋겠다. ',\n",
              " '3.6만큼 중립감정인 문장이다. 0.9만큼 놀람감정인 문장이다. 야생 꿩과 사육한 꿩의 생김새도 다르다',\n",
              " '3.5만큼 중립감정인 문장이다. 2.4만큼 슬픔감정인 문장이다. 그래, 나 같은 애도 역할이 있긴 하겠지',\n",
              " '4.0만큼 슬픔감정인 문장이다. 2.0만큼 공포감정인 문장이다. 부부동반 모임을 갖는데 아내가 참석하지 않으려 해서 속상해. 다른 부부들은 참석하는데 아내는 참석하기 싫어하니까 날 생각해주지 않는 것 같다고 느껴져. 아내와 둘이서만 시간을 가지고 나서 다시 한번 물어봐야겠어. ',\n",
              " '3.7만큼 중립감정인 문장이다. 2.3만큼 행복감정인 문장이다. 그가 맡은 일의 이미지와는 달리, 그른 이외로 순진하고 깔끔한 청년으로 피갈은 표현하고 있다',\n",
              " '6.3만큼 행복감정인 문장이다. -0.4만큼 공포감정인 문장이다. 직장 동료들이 성과를 잘 내어 주고 있어서 든든해. 내가 직원들의 도움을 많이 받는 것 같아. 별로 잘해준 것도 없는데 다들 고마워. ',\n",
              " '2.9만큼 중립감정인 문장이다. 2.3만큼 공포감정인 문장이다. 여름 즈음에는 단편영화 시나리오를 쓰고 있다는 말도 언뜻 들었던 것 같습니다',\n",
              " '3.6만큼 분노감정인 문장이다. 3.0만큼 혐오감정인 문장이다. 이런 바람을 일으킨 자들이 바로 지도급 인사로 드러나, 국민들은 제몫을 도둑맞은 것으로 생각한다',\n",
              " '2.7만큼 슬픔감정인 문장이다. 1.9만큼 놀람감정인 문장이다. 19년동안 내가 할아버지의 눈에서 눈물을 본것을 처음이다',\n",
              " '3.4만큼 행복감정인 문장이다. 3.4만큼 중립감정인 문장이다. 이 문장을 알게 된 이후, 나는 만들어낸 이야기를 사실이라 믿는 날들이 많아졌다',\n",
              " '3.8만큼 슬픔감정인 문장이다. 2.6만큼 공포감정인 문장이다. 거기에는 새봄이 되어도 봄의 전령사는 오지 않을 것 같았다',\n",
              " '2.7만큼 행복감정인 문장이다. 2.7만큼 중립감정인 문장이다. 아기 곰돌이는 아쉽지만 달님에게 인사를 해야해요',\n",
              " '1.5만큼 놀람감정인 문장이다. 1.2만큼 혐오감정인 문장이다. 진짜 이준호 체,,,,,,고,,,,,,,,,, 월요병 싹 날아갔다,,.......',\n",
              " '3.4만큼 행복감정인 문장이다. 2.4만큼 중립감정인 문장이다. 병의 고통과 싸우면서도 그는 제주의 신비를 찾아 마주했다',\n",
              " '4.3만큼 행복감정인 문장이다. 3.3만큼 중립감정인 문장이다. 당신이 당신만으로 존재하면 모두를 위한 당신이 된다',\n",
              " '3.9만큼 중립감정인 문장이다. 1.0만큼 슬픔감정인 문장이다. 친구를 잘사귀어야 된다.',\n",
              " '2.0만큼 중립감정인 문장이다. 0.9만큼 분노감정인 문장이다. 아내는 애를 업고 나는 술병과 고기 둬 근을 들고 걷기 시작했다',\n",
              " '3.3만큼 슬픔감정인 문장이다. 1.6만큼 놀람감정인 문장이다. 끝나고 심장 부여잡는거 다들 못보셨나.. 엄청 떤것같은데..ㅠ',\n",
              " '3.0만큼 중립감정인 문장이다. 1.7만큼 행복감정인 문장이다. 선생님은 1909년에 안중근 의사가 이토 히로부미를 처단했고, 결국 일본법원에서 사형을 선고받았다고 설명했다',\n",
              " '6.2만큼 행복감정인 문장이다. -0.3만큼 놀람감정인 문장이다. 와...!우리 아리니!!!병아린이라 옷도 아리니랑 잘 어울린다!!🐥ㅠ귀여웡!!😍',\n",
              " '3.9만큼 중립감정인 문장이다. -0.1만큼 행복감정인 문장이다. 멀리서 바라보면 산 중턱에 육중하리만큼 커다랗게 자리하고 있는 관청 겸 종교건물이기도 하다',\n",
              " '5.4만큼 행복감정인 문장이다. 1.4만큼 중립감정인 문장이다. 고향을 찾을 때마다 수호신처럼 길목을 지키며 가장 먼저 맞아주는 나무다',\n",
              " '2.3만큼 행복감정인 문장이다. 2.1만큼 놀람감정인 문장이다. 혼외정사는 그야말로 너무 황홀해 표현이 불가능하더란다',\n",
              " '5.1만큼 행복감정인 문장이다. 1.6만큼 중립감정인 문장이다. 수많은 무리들이 나와 상관없이 밝게 웃음 지으며 여유로이 지나가고 있었습니다.',\n",
              " '2.2만큼 분노감정인 문장이다. 2.1만큼 혐오감정인 문장이다. 입성을 허술히 했었던 것은 두말할 필요조차 없다',\n",
              " '3.5만큼 중립감정인 문장이다. 2.8만큼 행복감정인 문장이다. 마을버스가 그곳에 서기도 해서, 내 집을 찾아오는 이들에게 약도에 넣어 일러 주기도 한다',\n",
              " '4.6만큼 분노감정인 문장이다. 1.6만큼 슬픔감정인 문장이다. 아내가 친구들이랑 만나지 못하게 해서 짜증 나. 내가 친구들 만난다는데 왜 나서서 막는 건지 이해가 안 돼. 아내랑 진지하게 대화를 해봐야겠어. ',\n",
              " '4.2만큼 중립감정인 문장이다. 0.3만큼 공포감정인 문장이다. 즉 아래 대화를 참조하여 다섯 가지를 잘 살펴보는 것이 중요합니다',\n",
              " '5.5만큼 슬픔감정인 문장이다. -0.2만큼 중립감정인 문장이다. 보낼 말이 길어질수록 그리움이 더 길어져만 간다',\n",
              " '5.1만큼 슬픔감정인 문장이다. 0.2만큼 중립감정인 문장이다. 지나간 세월과 살아온 모습들이 주마등처럼 스쳐간다',\n",
              " '1.8만큼 혐오감정인 문장이다. 1.7만큼 놀람감정인 문장이다. ㄹㅇ 인싸 하이틴 여주들 모아놓은 것 같음',\n",
              " '3.8만큼 슬픔감정인 문장이다. 1.7만큼 놀람감정인 문장이다. 김이 토끼 그저 잠깐일 뿐인 친절에 공연히 마음을 줘 버린 내 탓.',\n",
              " '3.0만큼 놀람감정인 문장이다. 1.7만큼 공포감정인 문장이다. 대체 왜 그러는 지 정말 이해가 안갔습니다',\n",
              " '3.5만큼 중립감정인 문장이다. 0.8만큼 행복감정인 문장이다. 새우깡은 조용히 으깨어지는 과자가 아니어서 부서질 때 바드득 하는 소리를 낸다',\n",
              " '4.6만큼 슬픔감정인 문장이다. 1.4만큼 행복감정인 문장이다. 그런데 늘 나를 미워하시는 것만 같던 어머니 눈에 그렁그렁 눈물이 맺혀 있었다',\n",
              " '6.2만큼 행복감정인 문장이다. -0.5만큼 슬픔감정인 문장이다. 아니 ㅋㅋㅋㅋ 밑에 스탭분들 귀여우셔 ㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㄴㅋㅋㅋㅋㅋㅋㅋㅋ',\n",
              " '2.7만큼 중립감정인 문장이다. 1.2만큼 분노감정인 문장이다. 태깔 좋은 놈으로 골라 통째 달여 질끔 눈 감고 먹었다',\n",
              " '3.6만큼 중립감정인 문장이다. 0.8만큼 공포감정인 문장이다. 총소리가 들리고 온힘을 다해 매트를 넘고, 달리기 시작했다',\n",
              " '3.6만큼 중립감정인 문장이다. 1.9만큼 행복감정인 문장이다. 우리가 살아가는 생활에서 약속이나 희망을 이야기할 때, 영원이라는 단어를 쓰곤 합니다',\n",
              " '3.3만큼 행복감정인 문장이다. 2.5만큼 중립감정인 문장이다. 학창시절의 내 책가방은 참고서와 도시락으로 언제나 빵빵하였다',\n",
              " '5.0만큼 슬픔감정인 문장이다. 0.1만큼 분노감정인 문장이다. 그렇게 말해줘서 불쌍해진 나를 용서할 수가 없었다',\n",
              " '2.6만큼 중립감정인 문장이다. 2.6만큼 슬픔감정인 문장이다. 비가 내려 달이 보이지 않는 날에도 난 어두컴컴한 밤하늘을 보았다',\n",
              " '2.6만큼 놀람감정인 문장이다. 2.5만큼 행복감정인 문장이다. 컨셉만 내타입이었으면 ㄹㅇ 입덕각이네 년차 라이브가 무슨ㄷㄷ 괜히 이수만이 아끼는 그룹이 아니네요',\n",
              " '1.7만큼 공포감정인 문장이다. 1.6만큼 슬픔감정인 문장이다. 9시까지 맞춰가려면 어쩔 수 없는 노릇이다',\n",
              " '4.5만큼 중립감정인 문장이다. 1.4만큼 행복감정인 문장이다. 내가 글을 쓰는데 지침이 되어주는 분들의 필적이다',\n",
              " '5.3만큼 행복감정인 문장이다. 1.9만큼 중립감정인 문장이다. 꽤 오래된 스니커즈 그 허름한 편안함 널 만나러 가는 길은 설렘',\n",
              " '2.9만큼 놀람감정인 문장이다. 2.4만큼 중립감정인 문장이다. 사실 여기선 어부가 굉장히 인기 있는 직종인 만큼, 그가 어부인 것도 우연이 아니었다',\n",
              " '6.2만큼 행복감정인 문장이다. -0.3만큼 공포감정인 문장이다. 요즘 부모님이랑 관계가 많이 편안해졌어. 요즘 날씨가 좋으니까 같이 소풍을 가고 싶어.  ',\n",
              " '4.8만큼 분노감정인 문장이다. 1.2만큼 공포감정인 문장이다. 내가 은퇴 후에 가정 내에서 내 역할 비중이 많이 줄어들었어. 더 이상의 수입이 없으니 가정에서의 위치가 낮아졌다는 생각에 좌절감이 밀려오더라고. 집안일도 많이 도와주면서 가정을 위해 내가 할 수 있는 일들을 열심히 하려고 노력해야지. ',\n",
              " '2.6만큼 놀람감정인 문장이다. 2.4만큼 슬픔감정인 문장이다. 내게 먼저 데이트하자고 했던 사람한테 애프터를 신청했는데 거절당했어. 아직 명확하게 듣지 못했어. 얼버무리는 것 같아서 의도가 뭔지 모르겠어.   ',\n",
              " '1.1만큼 분노감정인 문장이다. 0.9만큼 놀람감정인 문장이다. 영호는 이미 의자에 반쯤 눕다시피 기대앉았고 영락이는 터미널을 둘러보고 온다고 하고는 휙 가버렸다',\n",
              " '3.7만큼 슬픔감정인 문장이다. 0.7만큼 공포감정인 문장이다. 나의목소리는 마이크에서 고래고래소리치는 당신에 의해 소리죽여 사라져간다',\n",
              " '2.5만큼 공포감정인 문장이다. 1.0만큼 놀람감정인 문장이다. 얼떨결에 상황을 놓치고만 나는 그저 어어소리만 내지를 뿐 되돌아 들어올 수밖에 없었다',\n",
              " '4.4만큼 분노감정인 문장이다. 1.8만큼 슬픔감정인 문장이다. 아빠는 나에 대해 잘 알지도 못 하면서 함부로 말해서 화가 나. 내가 나쁜 친구들하고 어울려 다닌다고 말씀하시는데 오해야. 좋은 친구들이라는 걸 집에 초대해서 알려드려야겠어. ',\n",
              " '3.4만큼 행복감정인 문장이다. 1.4만큼 중립감정인 문장이다. 그렇게 저는 공원 잔디 사이에 핀, 민들레 한송이 꺾어 가지고 그곳을 빠져 나갔습니다',\n",
              " '5.0만큼 행복감정인 문장이다. 1.4만큼 슬픔감정인 문장이다. 내 오랜 기억에 기다림에 새하얀 편지로 남겨진 그댄 언제나 나와 함께 있었죠',\n",
              " '3.0만큼 놀람감정인 문장이다. 2.7만큼 행복감정인 문장이다. 완전히 포기했던 광경을 보게 되자 나도 모르게 감탄사가 먼저 나왔다',\n",
              " '2.6만큼 혐오감정인 문장이다. 1.9만큼 분노감정인 문장이다. 아니 ㅋㅋㅋ 트와랑 비교하는거 볼려고 왔는데 왜다 영어댯이여',\n",
              " '2.7만큼 중립감정인 문장이다. 2.5만큼 슬픔감정인 문장이다. 난 낙엽이 떨어지는 가을밤을 좋아해 그 쓸쓸함']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# read txt file from line by line\n",
        "def read_txt(path):\n",
        "    with open(path, 'r', encoding='utf-8') as f:\n",
        "        lines = f.readlines()\n",
        "    return lines\n",
        "\n",
        "# make sampling function from the list\n",
        "def sampling(list_lines:list, n:int) -> list:\n",
        "    # sampling\n",
        "    list_lines = np.random.choice(list_lines, n)\n",
        "    list_lines = list(list_lines)\n",
        "    return list_lines"
      ],
      "metadata": {
        "id": "LR3nzRvPHbXh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get proportion of sentences where length is between 1 and 52\n",
        "min_char_length = 40\n",
        "max_char_length = 120\n",
        "list_to_use = list(filter(lambda x: len(x) > min_char_length and len(x) < max_char_length, list_train_text))\n",
        "\n",
        "print(f\"Length of dataset that is in between {min_char_length} and {max_char_length} is\" , len(list_to_use))\n",
        "print(f\"This is {round(len(list_to_use) / len(list_train_text) * 100, 2)} % of total dataset\")\n",
        "\n",
        "n = 20\n",
        "print(f\"Below are {n} samples of data to use\")\n",
        "sampling(list_to_use, n)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_P7aMdmKi-E0",
        "outputId": "2c33e478-bbb9-4bb7-c0d5-6e39052270dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of dataset that is in between 40 and 120 is 461329\n",
            "This is 93.37 % of total dataset\n",
            "Below are 20 samples of data to use\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['4.8만큼 중립감정인 문장이다. -0.3만큼 행복감정인 문장이다. 나는 다다음 정거장에서 내린 후 터벅터벅 걸어서 의자에 풀썩 앉았다',\n",
              " '5.6만큼 행복감정인 문장이다. 1.8만큼 중립감정인 문장이다. 바못 님의 독서실의 밤 글쓰기에 대한 바못 님의 생각 잘 읽었습니다',\n",
              " '2.0만큼 중립감정인 문장이다. 1.7만큼 혐오감정인 문장이다. 겨울철 소나무는 누굴 사랑하길래 이 한파속에서 초록의 자세를 견지하는건지',\n",
              " '3.0만큼 중립감정인 문장이다. 2.5만큼 행복감정인 문장이다. 오늘도 결국 비... 바람불고 소나기쳐도 결국엔 비가 온다. 오늘따라 유난히 비소리 잘들리네~~',\n",
              " '3.7만큼 중립감정인 문장이다. 2.9만큼 행복감정인 문장이다. 아무도 놀리지 않고 함께 어울려 놀았다',\n",
              " '4.6만큼 중립감정인 문장이다. 1.4만큼 행복감정인 문장이다. 그 애의 이름 세 글자면 향을 설명할 수 있는 말이 충분했다',\n",
              " '1.5만큼 행복감정인 문장이다. 1.1만큼 슬픔감정인 문장이다. 그리고 우리 엄마는, 어떤 일이 있더라도 아침만큼은 꼭 먹어야 한다!고 주장하는 분이시다',\n",
              " '3.4만큼 중립감정인 문장이다. 1.0만큼 놀람감정인 문장이다. 그것은 나의 프랑스 가족도 예외는 아니었다',\n",
              " '3.4만큼 행복감정인 문장이다. 1.8만큼 놀람감정인 문장이다. 둘다 자알 생겨따^^',\n",
              " '3.5만큼 중립감정인 문장이다. 2.1만큼 슬픔감정인 문장이다. 나는 물고기고, 바다를 헤엄치면서 아플 수도 있다고',\n",
              " '3.8만큼 분노감정인 문장이다. 2.5만큼 혐오감정인 문장이다. 뭔 팬티같은걸 입혀놨어 따수운 옷 입히라고',\n",
              " '4.8만큼 슬픔감정인 문장이다. 1.3만큼 공포감정인 문장이다. 잠깐의 그런 생각들은 날 전혀 원치 않았던 갈등의 기로에 올려놨다',\n",
              " '6.2만큼 행복감정인 문장이다. 0.6만큼 중립감정인 문장이다. 구름 안에 있는 공기의 흐름이 너무 좋아서 기분 좋다',\n",
              " '3.1만큼 행복감정인 문장이다. 2.9만큼 슬픔감정인 문장이다. 감히 가늠할 수도 없는 너의 큰마음 앞에 내가 한없이 작아지는 순간이었다.',\n",
              " '3.8만큼 중립감정인 문장이다. 0.7만큼 슬픔감정인 문장이다. 세상을 저 혼자서 살 수 없듯이 귀를 언제나 열어두어야 하리',\n",
              " '3.2만큼 중립감정인 문장이다. 0.5만큼 분노감정인 문장이다. 다음 날도 또 그 다음 날도',\n",
              " '1.9만큼 혐오감정인 문장이다. 1.7만큼 슬픔감정인 문장이다. 하지만 잘난 체 하면서 젊은 후배에게 잔소리나 하고 몽니만 부리다간 대접받지 못한다',\n",
              " '3.8만큼 분노감정인 문장이다. 2.9만큼 혐오감정인 문장이다. 이여자 변호하는사람은 누구냐 ! 이런 여자 변호하는사람 마음에 못느끼냐',\n",
              " '3.6만큼 중립감정인 문장이다. 0.5만큼 혐오감정인 문장이다. 그러나 화투 패를 쥐면 잔머리를 굴려야 하고 꼼수도 써야 한다',\n",
              " '3.5만큼 혐오감정인 문장이다. 3.1만큼 분노감정인 문장이다. 삼성 일가이제는 추락할 때이다']"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "stopwords = []\n",
        "\n",
        "# make post_process function\n",
        "def post_process(list_lines:list, stopwords) -> list:\n",
        "    # remove \\n\n",
        "    removed_lines = [line.strip() for line in list_lines]\n",
        "\n",
        "    # filter stopwords from the line item in list_lines using regex\n",
        "    if len(stopwords) > 0:\n",
        "        removed_lines = []\n",
        "        for line in list_lines:\n",
        "            for stopword in stopwords:\n",
        "                line = re.sub(stopword, '', line)\n",
        "            removed_lines.append(line)\n",
        "\n",
        "    # remove newlines\n",
        "    removed_lines = [sentence.replace('\\n', '') for sentence in removed_lines]\n",
        "\n",
        "    # strip whitespace\n",
        "    removed_lines = [sentence.strip() for sentence in removed_lines]\n",
        "\n",
        "    # remove one letter items\n",
        "    removed_lines = [sentence for sentence in removed_lines if len(sentence) > 1]\n",
        "\n",
        "    return removed_lines\n",
        "\n",
        "list_post_processed = post_process(list_to_use, stopwords)\n",
        "print(len(list_post_processed))\n",
        "\n",
        "n = 10\n",
        "sampling(list_post_processed, n)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nmhrTE82HbqS",
        "outputId": "d00af272-a429-448d-9176-9150744fc81f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "461329\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['6.0만큼 행복감정인 문장이다. -0.2만큼 놀람감정인 문장이다. 나는 그 고급스러운 분위기에 압도되고 말았다',\n",
              " '3.6만큼 슬픔감정인 문장이다. 1.2만큼 공포감정인 문장이다. 너를 뺀 모두가 너의 예정된 죽음을 알고 있다',\n",
              " '5.4만큼 슬픔감정인 문장이다. -0.2만큼 공포감정인 문장이다. 얼룩진 옆구리는 부종을 않는 아픔을 감추지 못하네요',\n",
              " '2.4만큼 공포감정인 문장이다. 1.4만큼 혐오감정인 문장이다. 그러고 보니 제법 잘되던 가게를 넘기고 떠난 전 주인의 의도가 미심쩍었다',\n",
              " '6.0만큼 행복감정인 문장이다. 1.0만큼 중립감정인 문장이다. 나는 편지 쓰는 일에 열심이었고 답장 받아 보는 일에 만족했다',\n",
              " '3.6만큼 슬픔감정인 문장이다. 2.6만큼 공포감정인 문장이다. 그래서 그 법이 나를 못 지켜줄 때가 있다',\n",
              " '2.6만큼 중립감정인 문장이다. 1.4만큼 놀람감정인 문장이다. 문득 새로운 미지의 세계를 찾아가는 길이 있으면 하는 터무니없는 생각에도 잠기게 한다',\n",
              " '2.7만큼 행복감정인 문장이다. 2.6만큼 슬픔감정인 문장이다. 날 보며 웃으시는 할머니를 한번이라도 마주 보며 활짝 웃을껄',\n",
              " '3.4만큼 중립감정인 문장이다. 2.1만큼 행복감정인 문장이다. 한참을 구경하다가 가격도 비싼 것 같지 않아 두 마리를 샀다',\n",
              " '3.5만큼 혐오감정인 문장이다. 2.2만큼 분노감정인 문장이다. 어머니의 가정에 대한 무책임은 충분히 지탄의 대상이 될 수 있다']"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenize"
      ],
      "metadata": {
        "id": "b-N44010IE8c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5gY-yznXIDaP",
        "outputId": "2b46ddb9-d67b-446c-a8bd-2601367cae4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.15.0-py3-none-any.whl (3.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.4 MB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 66.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 82.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.2.1-py3-none-any.whl (61 kB)\n",
            "\u001b[K     |████████████████████████████████| 61 kB 633 kB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 78.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.2.1 pyyaml-6.0 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.15.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!transformers-cli login"
      ],
      "metadata": {
        "id": "8Iqn61QokY2u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2Tokenizer, PreTrainedTokenizerFast\n",
        "\n",
        "# Load the Tokenizer: \"Fast\" means that the tokenizer code is written in Rust Lang\n",
        "tokenizer = PreTrainedTokenizerFast.from_pretrained(\n",
        "    CFG.model_dir,\n",
        "    bos_token=\"<s>\",\n",
        "    eos_token=\"</s>\",\n",
        "    unk_token=\"<unk>\",\n",
        "    pad_token=\"<pad>\",\n",
        "    mask_token=\"<mask>\",\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217,
          "referenced_widgets": [
            "0de2f9d2c343424cb85cd01f83be89a8",
            "8e64d363bc7f4282994a3977e210733b",
            "3134ebd7f7054d1a82670d300e33ef1e",
            "8bd427622f8e4c8cba2a1b97593f68b7",
            "85321a204daf4b05964a21012a74fff1",
            "00ba62ad89dc4816b5724c08a1bf4908",
            "2ee86c1d7b7342819f01e915b8918f74",
            "db8e581fc5fe419ab18c585ecc5ae514",
            "15d530cbf08845cca4b9b632e04df536",
            "59f154abbe264f02a7a51bbd5f46997b",
            "561e9063ac98439fa91450f2c74ed506",
            "a49eb86aeb2347d4b67887d3b6e0a801",
            "fd58458f4e3945a2a729c21d166383bf",
            "998ccf5aaff54de49c8665ca2e7f6dc5",
            "ba9facc8b9c64d81896f1ab4fb7cbb11",
            "e202dd927ecb4bc5b8eac6e53efcf57e",
            "8815ae252f7546d79015b17fe80ddbb6",
            "69144bc2a17e48f78a9f6648d6238ccf",
            "9ff35d95506c4fa2850c02ad578466f4",
            "a982a9c126b844db889c2ca500f65e09",
            "062331f0fd6a4c33a8137d271f3bc60d",
            "15f62d1012ad48279c8a01db789cc6a2",
            "65e01966d0af4b7b97164761fb73054c",
            "70f948c92b1849c6997904ab358ceeb5",
            "a302f19fd0e64eb680aae1f5e4fc9d13",
            "29c52b78367b442ea066dff0942dea9b",
            "2ba2590f5ebd40c1908892ae2b5d5c65",
            "863aba9be4d04c98819f31e1e6c9ab25",
            "0a088055497042619bfd4c27ea947902",
            "3dcb342dec604fb7afd4aaee002785ce",
            "7f6a2502324648fcaabdd77d4730921e",
            "585ea296916f4459831a7b770536a9fb",
            "ee7c927b260a47c5b85ee4145d81193f",
            "03bc72b196444cfca519a0eb70070c76",
            "d5ebee26b6be49868c87189ef0bcdbf5",
            "6a06b562f0f84d1f966d6f2527ab8ec9",
            "55cc86553b90462eb60bce68d95db4b4",
            "7343cf69f7f34ad1b5d0844239a78753",
            "8b16172b5015401dbc5b2da9efba5252",
            "3ea221fb780c49c890aaec6a60a58e44",
            "2d1791c683b74b9e86d84a9495c319cf",
            "8ef65155e05b483683314cebac960310",
            "44c9325b1fe84ccab8a262ac7a40a025",
            "cb7c71fa18194a5fb1c471e88140d173"
          ]
        },
        "id": "cYYcUCC8H9X8",
        "outputId": "830b5159-b59f-4e76-c52b-899ed870d944"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0de2f9d2c343424cb85cd01f83be89a8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/109 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a49eb86aeb2347d4b67887d3b6e0a801",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "65e01966d0af4b7b97164761fb73054c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.00M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "03bc72b196444cfca519a0eb70070c76",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/731 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
            "The class this function is called from is 'PreTrainedTokenizerFast'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get the length of the individual items in tokenized input_ids\n",
        "tokenized_input_ids = tokenizer(list_post_processed).input_ids\n",
        "tokenized_length = [len(item) for item in tokenized_input_ids]"
      ],
      "metadata": {
        "id": "X2C-R23PIHuO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# check the length distribution of the list with x ticks divided by 1 tokens\n",
        "plt.hist(tokenized_length, bins=np.arange(0, max(tokenized_length)+1, 1))\n",
        "print(max(tokenized_length)+1)\n",
        "plt.xlabel(\"Length of the tokenized sentence\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "KQr_VTZDICM7",
        "outputId": "b06f5a32-f800-4300-fe7a-02d76a39a7f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "90\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get proportion of sentences where length is between 0 and 32\n",
        "min_token_length = 20\n",
        "max_token_length = 42\n",
        "list_between = list(filter(lambda x: x > min_token_length and x < max_token_length, tokenized_length))\n",
        "print(len(list_between) , len(list_between) / len(list_to_use))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZIPwqA4IJY3",
        "outputId": "c34ccbb4-c054-42a5-fe65-ce150a22413a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "420599 0.9117115984470953\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# you can overwrite with the length you desire\n",
        "max_token_length = 42\n",
        "CFG.max_token_length = max_token_length"
      ],
      "metadata": {
        "id": "IF_EsPEQIP8v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Finetune Pretrained KoGPT Trinity GPTLM Model"
      ],
      "metadata": {
        "id": "gZZTNtJeOHie"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2Config\n",
        "\n",
        "# set config and override with custom configuration\n",
        "config = GPT2Config.from_pretrained(CFG.model_dir)\n",
        "config"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lO6cR4QeJXgm",
        "outputId": "801f7fc2-d91e-4277-db02-c76ba5d77f81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPT2Config {\n",
              "  \"activation_function\": \"gelu_new\",\n",
              "  \"architectures\": [\n",
              "    \"GPT2LMHeadModel\"\n",
              "  ],\n",
              "  \"attn_pdrop\": 0.1,\n",
              "  \"bos_token_id\": 0,\n",
              "  \"embd_pdrop\": 0.1,\n",
              "  \"eos_token_id\": 8,\n",
              "  \"gradient_checkpointing\": false,\n",
              "  \"initializer_range\": 0.02,\n",
              "  \"layer_norm_epsilon\": 1e-05,\n",
              "  \"model_type\": \"gpt2\",\n",
              "  \"n_ctx\": 1024,\n",
              "  \"n_embd\": 1920,\n",
              "  \"n_head\": 16,\n",
              "  \"n_inner\": 7680,\n",
              "  \"n_layer\": 24,\n",
              "  \"n_positions\": 1024,\n",
              "  \"pad_token_id\": 8,\n",
              "  \"reorder_and_upcast_attn\": false,\n",
              "  \"resid_pdrop\": 0.1,\n",
              "  \"scale_attn_by_inverse_layer_idx\": false,\n",
              "  \"scale_attn_weights\": true,\n",
              "  \"summary_activation\": null,\n",
              "  \"summary_first_dropout\": 0.1,\n",
              "  \"summary_proj_to_labels\": true,\n",
              "  \"summary_type\": \"cls_index\",\n",
              "  \"summary_use_proj\": true,\n",
              "  \"transformers_version\": \"4.15.0\",\n",
              "  \"use_cache\": true,\n",
              "  \"vocab_size\": 51200\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SOIpf0-UJaXD",
        "outputId": "1e3fbdc5-496d-4337-f59c-4238c190207d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Dec 24 20:03:43 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  A100-SXM4-40GB      Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   33C    P0    43W / 400W |      0MiB / 40536MiB |      0%      Default |\n",
            "|                               |                      |             Disabled |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2LMHeadModel\n",
        "\n",
        "# Attach Language model Head to the pretrained GPT model\n",
        "model = GPT2LMHeadModel.from_pretrained(CFG.model_dir) # KoGPT3 shares the same structure as KoGPT2. \n",
        "\n",
        "\"\"\"\n",
        "**labels**: (`optional`) ``torch.LongTensor`` of shape ``(batch_size, sequence_length)``:\n",
        "    Labels for language modeling.\n",
        "    Note that the labels **are shifted** inside the model, i.e. you can set ``lm_labels = input_ids``\n",
        "    Indices are selected in ``[-100, 0, ..., config.vocab_size]``\n",
        "    All labels set to ``-100`` are ignored (masked), the loss is only\n",
        "    computed for labels in ``[0, ..., config.vocab_size]``\n",
        "\n",
        "Outputs: `Tuple` comprising various elements depending on the configuration (config) and inputs:\n",
        "**loss**: (`optional`, returned when ``labels`` is provided) ``torch.FloatTensor`` of shape ``(1,)``:\n",
        "    Language modeling loss.\n",
        "**prediction_scores**: ``torch.FloatTensor`` of shape ``(batch_size, sequence_length, config.vocab_size)``\n",
        "    Prediction scores of the language modeling head (scores for each vocabulary token before SoftMax).\n",
        "**past**:\n",
        "    list of ``torch.FloatTensor`` (one for each layer) of shape ``(2, batch_size, num_heads, sequence_length, embed_size_per_head)``:\n",
        "    that contains pre-computed hidden-states (key and values in the attention blocks).\n",
        "    Can be used (see `past` input) to speed up sequential decoding. The token ids which have their past given to this model\n",
        "    should not be passed as input ids as they have already been computed.\n",
        "**hidden_states**: (`optional`, returned when ``config.output_hidden_states=True``)\n",
        "    list of ``torch.FloatTensor`` (one for the output of each layer + the output of the embeddings)\n",
        "    of shape ``(batch_size, sequence_length, hidden_size)``:\n",
        "    Hidden-states of the model at the output of each layer plus the initial embedding outputs.\n",
        "**attentions**: (`optional`, returned when ``config.output_attentions=True``)\n",
        "    list of ``torch.FloatTensor`` (one for each layer) of shape ``(batch_size, num_heads, sequence_length, sequence_length)``:\n",
        "    Attentions weights after the attention softmax, used to compute the weighted average in the self-attention heads.\n",
        "\n",
        "Examples::\n",
        "\n",
        "    import torch\n",
        "    from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
        "\n",
        "    tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "    model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
        "\n",
        "    input_ids = torch.tensor(tokenizer.encode(\"Hello, my dog is cute\", add_special_tokens=True)).unsqueeze(0)  # Batch size 1\n",
        "    outputs = model(input_ids, labels=input_ids)\n",
        "    loss, logits = outputs[:2]\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284,
          "referenced_widgets": [
            "94d1a56f825942828294bd9b1d38b460",
            "8b02aa64a9634b23bf03a3326f9e1782",
            "1ff1efab8d9d492b947eb141544cd69d",
            "fcad3236285144ed9cda734f501f1cb4",
            "15dea6ffa0f34eb0af0c14486f9aecd9",
            "b848bff75d694b37a5e255a5ba336016",
            "3d51af14451a4791a07c2b051f2958fc",
            "0410f92dc0fe46e284535dedc5195171",
            "7cde95b9af5b47c691b35920f3c8afd2",
            "245a303d935149ddbd7719e07ddd9d5f",
            "9a357c346fe34634978a157c7ed13227"
          ]
        },
        "id": "DCAaPn9hJcBN",
        "outputId": "8dda47cb-9835-4f39-b6f8-9854218a3728"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "94d1a56f825942828294bd9b1d38b460",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/4.35G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n**labels**: (`optional`) ``torch.LongTensor`` of shape ``(batch_size, sequence_length)``:\\n    Labels for language modeling.\\n    Note that the labels **are shifted** inside the model, i.e. you can set ``lm_labels = input_ids``\\n    Indices are selected in ``[-100, 0, ..., config.vocab_size]``\\n    All labels set to ``-100`` are ignored (masked), the loss is only\\n    computed for labels in ``[0, ..., config.vocab_size]``\\n\\nOutputs: `Tuple` comprising various elements depending on the configuration (config) and inputs:\\n**loss**: (`optional`, returned when ``labels`` is provided) ``torch.FloatTensor`` of shape ``(1,)``:\\n    Language modeling loss.\\n**prediction_scores**: ``torch.FloatTensor`` of shape ``(batch_size, sequence_length, config.vocab_size)``\\n    Prediction scores of the language modeling head (scores for each vocabulary token before SoftMax).\\n**past**:\\n    list of ``torch.FloatTensor`` (one for each layer) of shape ``(2, batch_size, num_heads, sequence_length, embed_size_per_head)``:\\n    that contains pre-computed hidden-states (key and values in the attention blocks).\\n    Can be used (see `past` input) to speed up sequential decoding. The token ids which have their past given to this model\\n    should not be passed as input ids as they have already been computed.\\n**hidden_states**: (`optional`, returned when ``config.output_hidden_states=True``)\\n    list of ``torch.FloatTensor`` (one for the output of each layer + the output of the embeddings)\\n    of shape ``(batch_size, sequence_length, hidden_size)``:\\n    Hidden-states of the model at the output of each layer plus the initial embedding outputs.\\n**attentions**: (`optional`, returned when ``config.output_attentions=True``)\\n    list of ``torch.FloatTensor`` (one for each layer) of shape ``(batch_size, num_heads, sequence_length, sequence_length)``:\\n    Attentions weights after the attention softmax, used to compute the weighted average in the self-attention heads.\\n\\nExamples::\\n\\n    import torch\\n    from transformers import GPT2Tokenizer, GPT2LMHeadModel\\n\\n    tokenizer = GPT2Tokenizer.from_pretrained(\\'gpt2\\')\\n    model = GPT2LMHeadModel.from_pretrained(\\'gpt2\\')\\n\\n    input_ids = torch.tensor(tokenizer.encode(\"Hello, my dog is cute\", add_special_tokens=True)).unsqueeze(0)  # Batch size 1\\n    outputs = model(input_ids, labels=input_ids)\\n    loss, logits = outputs[:2]\\n\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_43V-GCwa2B",
        "outputId": "04e7074f-475b-474a-bf56-44bb20fcdbc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wandb\n",
            "  Downloading wandb-0.12.9-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (6.0)\n",
            "Collecting subprocess32>=3.5.3\n",
            "  Downloading subprocess32-3.5.4.tar.gz (97 kB)\n",
            "\u001b[K     |████████████████████████████████| 97 kB 9.0 MB/s \n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting yaspin>=1.0.0\n",
            "  Downloading yaspin-2.1.0-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.2)\n",
            "Collecting GitPython>=1.0.0\n",
            "  Downloading GitPython-3.1.24-py3-none-any.whl (180 kB)\n",
            "\u001b[K     |████████████████████████████████| 180 kB 82.7 MB/s \n",
            "\u001b[?25hCollecting shortuuid>=0.5.0\n",
            "  Downloading shortuuid-1.0.8-py3-none-any.whl (9.5 kB)\n",
            "Collecting configparser>=3.8.1\n",
            "  Downloading configparser-5.2.0-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.5.1-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[K     |████████████████████████████████| 140 kB 87.7 MB/s \n",
            "\u001b[?25hCollecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (3.10.0.2)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 2.3 MB/s \n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied: termcolor<2.0.0,>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from yaspin>=1.0.0->wandb) (1.1.0)\n",
            "Building wheels for collected packages: subprocess32, pathtools\n",
            "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for subprocess32: filename=subprocess32-3.5.4-py3-none-any.whl size=6502 sha256=20c31bd5173f22afc5a751b4700bb27555a8fcfa4dc8aa15ef004db6a46f1ce4\n",
            "  Stored in directory: /root/.cache/pip/wheels/50/ca/fa/8fca8d246e64f19488d07567547ddec8eb084e8c0d7a59226a\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8807 sha256=074b5525665f4d5043573bf7b3565b122736262f71f76a810b51188be953620b\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n",
            "Successfully built subprocess32 pathtools\n",
            "Installing collected packages: smmap, gitdb, yaspin, subprocess32, shortuuid, sentry-sdk, pathtools, GitPython, docker-pycreds, configparser, wandb\n",
            "Successfully installed GitPython-3.1.24 configparser-5.2.0 docker-pycreds-0.4.0 gitdb-4.0.9 pathtools-0.1.2 sentry-sdk-1.5.1 shortuuid-1.0.8 smmap-5.0.0 subprocess32-3.5.4 wandb-0.12.9 yaspin-2.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# move the model to device\n",
        "if torch.cuda.is_available() and CFG.DEBUG == False:\n",
        "    device = torch.device(\"cuda:0\")\n",
        "elif CFG.DEBUG == True:\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "print(f\"current device that is training on: {device}\")\n",
        "model = model.to(device)\n",
        "model.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BThAf0A7Jd68",
        "outputId": "2bdfd5b2-d419-4ff8-f3fe-c74bc6369b07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "current device that is training on: cuda:0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPT2LMHeadModel(\n",
              "  (transformer): GPT2Model(\n",
              "    (wte): Embedding(51200, 1920)\n",
              "    (wpe): Embedding(1024, 1920)\n",
              "    (drop): Dropout(p=0.1, inplace=False)\n",
              "    (h): ModuleList(\n",
              "      (0): GPT2Block(\n",
              "        (ln_1): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): GPT2Block(\n",
              "        (ln_1): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (2): GPT2Block(\n",
              "        (ln_1): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (3): GPT2Block(\n",
              "        (ln_1): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (4): GPT2Block(\n",
              "        (ln_1): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (5): GPT2Block(\n",
              "        (ln_1): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (6): GPT2Block(\n",
              "        (ln_1): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (7): GPT2Block(\n",
              "        (ln_1): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (8): GPT2Block(\n",
              "        (ln_1): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (9): GPT2Block(\n",
              "        (ln_1): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (10): GPT2Block(\n",
              "        (ln_1): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (11): GPT2Block(\n",
              "        (ln_1): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (12): GPT2Block(\n",
              "        (ln_1): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (13): GPT2Block(\n",
              "        (ln_1): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (14): GPT2Block(\n",
              "        (ln_1): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (15): GPT2Block(\n",
              "        (ln_1): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (16): GPT2Block(\n",
              "        (ln_1): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (17): GPT2Block(\n",
              "        (ln_1): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (18): GPT2Block(\n",
              "        (ln_1): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (19): GPT2Block(\n",
              "        (ln_1): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (20): GPT2Block(\n",
              "        (ln_1): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (21): GPT2Block(\n",
              "        (ln_1): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (22): GPT2Block(\n",
              "        (ln_1): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (23): GPT2Block(\n",
              "        (ln_1): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_f): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=1920, out_features=51200, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBbGbl75JfLY",
        "outputId": "d687031b-309c-4136-9b02-aa65864a27dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Dec 24 20:05:48 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  A100-SXM4-40GB      Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   33C    P0    48W / 400W |   6550MiB / 40536MiB |      0%      Default |\n",
            "|                               |                      |             Disabled |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# https://huggingface.co/transformers/custom_datasets.html\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    \"\"\" CustomDataset class for poetic sentences \"\"\"\n",
        "    def __init__(self, list_dataset, tokenizer):\n",
        "\n",
        "        self.list_dataset = list_dataset\n",
        "        self.tokenizer = tokenizer\n",
        "        self.tokenized_sentences = self.tokenizer(\n",
        "            list_dataset,\n",
        "            return_tensors=\"pt\",\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            max_length=CFG.max_token_length,\n",
        "            add_special_tokens=True,\n",
        "            return_token_type_ids=False,\n",
        "            )\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        encoded_dict = {key: val[idx] for key, val in self.tokenized_sentences.items()}\n",
        "        encoded_dict[\"labels\"] = encoded_dict[\"input_ids\"].clone() # gpt has same labels as input_ids: https://github.com/huggingface/notebooks/blob/master/examples/language_modeling.ipynb\n",
        "        return encoded_dict\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.list_dataset)\n"
      ],
      "metadata": {
        "id": "FyXTDUpbJhdQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kor_poetic_dataset = CustomDataset(list_post_processed, tokenizer)\n",
        "# kor_poetic_eval_dataset = CustomDataset(list_post_processed[:5000], tokenizer)\n",
        "print(len(kor_poetic_dataset))\n",
        "# print(len(kor_poetic_eval_dataset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8YVbt4f3Jkcs",
        "outputId": "018a4685-54fb-4704-dd55-70f063f18169"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "461329\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "list_post_processed_eval = random.choices(list_train_text, k = 5000)\n",
        "kor_poetic_eval_dataset = CustomDataset(list_post_processed_eval, tokenizer)"
      ],
      "metadata": {
        "id": "d7dmcOdMAt_W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(kor_poetic_dataset[3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "umSazmoyJkYE",
        "outputId": "0ff09995-e5cd-4964-a001-a30f9e9b8633"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': tensor([30106, 31922, 31299, 31970, 18808, 25981, 25824, 41460, 30085, 29992,\n",
            "        30891, 31299, 38431, 18808, 25981, 25824, 41460, 30085, 30678, 37636,\n",
            "        30004, 25737, 23134, 25780, 33928,   377,   390,     3,     3,     3,\n",
            "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "            3,     3]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'labels': tensor([30106, 31922, 31299, 31970, 18808, 25981, 25824, 41460, 30085, 29992,\n",
            "        30891, 31299, 38431, 18808, 25981, 25824, 41460, 30085, 30678, 37636,\n",
            "        30004, 25737, 23134, 25780, 33928,   377,   390,     3,     3,     3,\n",
            "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
            "            3,     3])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn import CrossEntropyLoss\n",
        "from transformers.optimization import AdamW\n",
        "\n",
        "CFG.learning_rate = 2e-5\n",
        "# criterion = CrossEntropyLoss()\n",
        "# optimizer = AdamW(model.parameters(), lr=CFG.learning_rate)"
      ],
      "metadata": {
        "id": "oTicvnHGJkLV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://github.com/huggingface/transformers/blob/master/examples/pytorch/language-modeling/run_clm.py\n",
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "CFG.num_epochs = 4\n",
        "CFG.train_batch_size = 42\n",
        "CFG.evaluation_steps = 1000\n",
        "\n",
        "# https://huggingface.co/transformers/_modules/transformers/training_args.html\n",
        "training_args = TrainingArguments(\n",
        "    # train configs\n",
        "    num_train_epochs=CFG.num_epochs,  # total number of training epochs\n",
        "    per_device_train_batch_size=CFG.train_batch_size,  # batch size per device during training \n",
        "    per_device_eval_batch_size=CFG.train_batch_size,\n",
        "    learning_rate=CFG.learning_rate,  # learning rate,\n",
        "    # warmup_steps=CFG.warmup_steps,  # number of warmup steps for learning rate scheduler\n",
        "    weight_decay=CFG.weight_decay,  # strength of weight decay\n",
        "    \n",
        "    # evaluating\n",
        "    evaluation_strategy = \"steps\",\n",
        "    eval_steps = CFG.evaluation_steps,\n",
        "    load_best_model_at_end = True,\n",
        "    metric_for_best_model = 'loss',\n",
        "    \n",
        "    # logging\n",
        "    logging_steps=CFG.evaluation_steps,              # log saving step.\n",
        "    logging_dir=\"./logs\",  # directory for storing logs, \n",
        "    report_to=\"wandb\",  # report to wandb\n",
        "    run_name = 'kogpt-conditional',\n",
        "\n",
        "    # save configs\n",
        "    save_steps=CFG.evaluation_steps,\n",
        "    output_dir=\"./results\",  # output directory\n",
        "    save_total_limit= 3,              # number of total save model.\n",
        ")\n",
        "\n",
        "# https://github.com/huggingface/transformers/blob/master/src/transformers/trainer.py\n",
        "trainer = Trainer(\n",
        "    model=model,  # the instantiated 🤗 Transformers model to be trained\n",
        "    args=training_args,  # training arguments, defined above\n",
        "    train_dataset=kor_poetic_dataset,  # training dataset, no evaluation dataset\n",
        "    eval_dataset=kor_poetic_eval_dataset,  # evaluation dataset is same as training dataset\n",
        ")"
      ],
      "metadata": {
        "id": "b8juFUXKJ-Dk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0nQSq3InalkQ",
        "outputId": "7d3d7562-9e65-461d-fcb3-bb72b30d2e50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Dec 24 20:07:56 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  A100-SXM4-40GB      Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   33C    P0    48W / 400W |   6710MiB / 40536MiB |      0%      Default |\n",
            "|                               |                      |             Disabled |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "zBwf7lFfaQ-j",
        "outputId": "c93d10d0-29d9-4be7-9198-f9abdf811f71"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "***** Running training *****\n",
            "  Num examples = 461329\n",
            "  Num Epochs = 4\n",
            "  Instantaneous batch size per device = 42\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 42\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 43940\n",
            "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "                    Syncing run <strong><a href=\"https://wandb.ai/snoop2head/huggingface/runs/1kq8es3y\" target=\"_blank\">kogpt-conditional</a></strong> to <a href=\"https://wandb.ai/snoop2head/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
              "\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='12178' max='43940' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [12178/43940 1:55:51 < 5:02:12, 1.75 it/s, Epoch 1.11/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>1.887400</td>\n",
              "      <td>1.824687</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>1.828900</td>\n",
              "      <td>1.777723</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>1.808700</td>\n",
              "      <td>1.741976</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>1.785200</td>\n",
              "      <td>1.701073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>1.769100</td>\n",
              "      <td>1.667463</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>1.747000</td>\n",
              "      <td>1.632592</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7000</td>\n",
              "      <td>1.731800</td>\n",
              "      <td>1.597418</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8000</td>\n",
              "      <td>1.715500</td>\n",
              "      <td>1.564882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9000</td>\n",
              "      <td>1.692700</td>\n",
              "      <td>1.531193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10000</td>\n",
              "      <td>1.683400</td>\n",
              "      <td>1.506095</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11000</td>\n",
              "      <td>1.657900</td>\n",
              "      <td>1.464887</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12000</td>\n",
              "      <td>1.442500</td>\n",
              "      <td>1.425498</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 5000\n",
            "  Batch size = 42\n",
            "Saving model checkpoint to ./results/checkpoint-1000\n",
            "Configuration saved in ./results/checkpoint-1000/config.json\n",
            "Model weights saved in ./results/checkpoint-1000/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5000\n",
            "  Batch size = 42\n",
            "Saving model checkpoint to ./results/checkpoint-2000\n",
            "Configuration saved in ./results/checkpoint-2000/config.json\n",
            "Model weights saved in ./results/checkpoint-2000/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5000\n",
            "  Batch size = 42\n",
            "Saving model checkpoint to ./results/checkpoint-3000\n",
            "Configuration saved in ./results/checkpoint-3000/config.json\n",
            "Model weights saved in ./results/checkpoint-3000/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5000\n",
            "  Batch size = 42\n",
            "Saving model checkpoint to ./results/checkpoint-4000\n",
            "Configuration saved in ./results/checkpoint-4000/config.json\n",
            "Model weights saved in ./results/checkpoint-4000/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-1000] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5000\n",
            "  Batch size = 42\n",
            "Saving model checkpoint to ./results/checkpoint-5000\n",
            "Configuration saved in ./results/checkpoint-5000/config.json\n",
            "Model weights saved in ./results/checkpoint-5000/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-2000] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5000\n",
            "  Batch size = 42\n",
            "Saving model checkpoint to ./results/checkpoint-6000\n",
            "Configuration saved in ./results/checkpoint-6000/config.json\n",
            "Model weights saved in ./results/checkpoint-6000/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-3000] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5000\n",
            "  Batch size = 42\n",
            "Saving model checkpoint to ./results/checkpoint-7000\n",
            "Configuration saved in ./results/checkpoint-7000/config.json\n",
            "Model weights saved in ./results/checkpoint-7000/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-4000] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5000\n",
            "  Batch size = 42\n",
            "Saving model checkpoint to ./results/checkpoint-8000\n",
            "Configuration saved in ./results/checkpoint-8000/config.json\n",
            "Model weights saved in ./results/checkpoint-8000/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-5000] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5000\n",
            "  Batch size = 42\n",
            "Saving model checkpoint to ./results/checkpoint-9000\n",
            "Configuration saved in ./results/checkpoint-9000/config.json\n",
            "Model weights saved in ./results/checkpoint-9000/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-6000] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5000\n",
            "  Batch size = 42\n",
            "Saving model checkpoint to ./results/checkpoint-10000\n",
            "Configuration saved in ./results/checkpoint-10000/config.json\n",
            "Model weights saved in ./results/checkpoint-10000/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-7000] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5000\n",
            "  Batch size = 42\n",
            "Saving model checkpoint to ./results/checkpoint-11000\n",
            "Configuration saved in ./results/checkpoint-11000/config.json\n",
            "Model weights saved in ./results/checkpoint-11000/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-8000] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5000\n",
            "  Batch size = 42\n",
            "Saving model checkpoint to ./results/checkpoint-12000\n",
            "Configuration saved in ./results/checkpoint-12000/config.json\n",
            "Model weights saved in ./results/checkpoint-12000/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-9000] due to args.save_total_limit\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='43940' max='43940' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [43940/43940 6:58:01, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>1.887400</td>\n",
              "      <td>1.824687</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>1.828900</td>\n",
              "      <td>1.777723</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>1.808700</td>\n",
              "      <td>1.741976</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>1.785200</td>\n",
              "      <td>1.701073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>1.769100</td>\n",
              "      <td>1.667463</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>1.747000</td>\n",
              "      <td>1.632592</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7000</td>\n",
              "      <td>1.731800</td>\n",
              "      <td>1.597418</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8000</td>\n",
              "      <td>1.715500</td>\n",
              "      <td>1.564882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9000</td>\n",
              "      <td>1.692700</td>\n",
              "      <td>1.531193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10000</td>\n",
              "      <td>1.683400</td>\n",
              "      <td>1.506095</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11000</td>\n",
              "      <td>1.657900</td>\n",
              "      <td>1.464887</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12000</td>\n",
              "      <td>1.442500</td>\n",
              "      <td>1.425498</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13000</td>\n",
              "      <td>1.435500</td>\n",
              "      <td>1.400397</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14000</td>\n",
              "      <td>1.432900</td>\n",
              "      <td>1.376942</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15000</td>\n",
              "      <td>1.433100</td>\n",
              "      <td>1.354059</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16000</td>\n",
              "      <td>1.423900</td>\n",
              "      <td>1.333440</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17000</td>\n",
              "      <td>1.424600</td>\n",
              "      <td>1.313987</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18000</td>\n",
              "      <td>1.413100</td>\n",
              "      <td>1.295556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19000</td>\n",
              "      <td>1.407600</td>\n",
              "      <td>1.275855</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20000</td>\n",
              "      <td>1.411200</td>\n",
              "      <td>1.259898</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21000</td>\n",
              "      <td>1.403800</td>\n",
              "      <td>1.240414</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22000</td>\n",
              "      <td>1.386800</td>\n",
              "      <td>1.206830</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23000</td>\n",
              "      <td>1.191500</td>\n",
              "      <td>1.182023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24000</td>\n",
              "      <td>1.191700</td>\n",
              "      <td>1.166274</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25000</td>\n",
              "      <td>1.194300</td>\n",
              "      <td>1.153407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26000</td>\n",
              "      <td>1.189300</td>\n",
              "      <td>1.139796</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27000</td>\n",
              "      <td>1.195300</td>\n",
              "      <td>1.125401</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28000</td>\n",
              "      <td>1.192900</td>\n",
              "      <td>1.113017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29000</td>\n",
              "      <td>1.195000</td>\n",
              "      <td>1.100357</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30000</td>\n",
              "      <td>1.194700</td>\n",
              "      <td>1.089126</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31000</td>\n",
              "      <td>1.194800</td>\n",
              "      <td>1.077124</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32000</td>\n",
              "      <td>1.193700</td>\n",
              "      <td>1.064188</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33000</td>\n",
              "      <td>1.182200</td>\n",
              "      <td>1.042439</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34000</td>\n",
              "      <td>1.037900</td>\n",
              "      <td>1.032965</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35000</td>\n",
              "      <td>1.036300</td>\n",
              "      <td>1.024894</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36000</td>\n",
              "      <td>1.043300</td>\n",
              "      <td>1.017493</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37000</td>\n",
              "      <td>1.042400</td>\n",
              "      <td>1.010666</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38000</td>\n",
              "      <td>1.040800</td>\n",
              "      <td>1.003896</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39000</td>\n",
              "      <td>1.041600</td>\n",
              "      <td>0.998919</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40000</td>\n",
              "      <td>1.040800</td>\n",
              "      <td>0.994306</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41000</td>\n",
              "      <td>1.039400</td>\n",
              "      <td>0.989526</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42000</td>\n",
              "      <td>1.039800</td>\n",
              "      <td>0.986574</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43000</td>\n",
              "      <td>1.035400</td>\n",
              "      <td>0.984395</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 5000\n",
            "  Batch size = 42\n",
            "Saving model checkpoint to ./results/checkpoint-13000\n",
            "Configuration saved in ./results/checkpoint-13000/config.json\n",
            "Model weights saved in ./results/checkpoint-13000/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-10000] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5000\n",
            "  Batch size = 42\n",
            "Saving model checkpoint to ./results/checkpoint-14000\n",
            "Configuration saved in ./results/checkpoint-14000/config.json\n",
            "Model weights saved in ./results/checkpoint-14000/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-11000] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5000\n",
            "  Batch size = 42\n",
            "Saving model checkpoint to ./results/checkpoint-15000\n",
            "Configuration saved in ./results/checkpoint-15000/config.json\n",
            "Model weights saved in ./results/checkpoint-15000/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-12000] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5000\n",
            "  Batch size = 42\n",
            "Saving model checkpoint to ./results/checkpoint-16000\n",
            "Configuration saved in ./results/checkpoint-16000/config.json\n",
            "Model weights saved in ./results/checkpoint-16000/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-13000] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5000\n",
            "  Batch size = 42\n",
            "Saving model checkpoint to ./results/checkpoint-17000\n",
            "Configuration saved in ./results/checkpoint-17000/config.json\n",
            "Model weights saved in ./results/checkpoint-17000/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-14000] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5000\n",
            "  Batch size = 42\n",
            "Saving model checkpoint to ./results/checkpoint-18000\n",
            "Configuration saved in ./results/checkpoint-18000/config.json\n",
            "Model weights saved in ./results/checkpoint-18000/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-15000] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5000\n",
            "  Batch size = 42\n",
            "Saving model checkpoint to ./results/checkpoint-19000\n",
            "Configuration saved in ./results/checkpoint-19000/config.json\n",
            "Model weights saved in ./results/checkpoint-19000/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-16000] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5000\n",
            "  Batch size = 42\n",
            "Saving model checkpoint to ./results/checkpoint-20000\n",
            "Configuration saved in ./results/checkpoint-20000/config.json\n",
            "Model weights saved in ./results/checkpoint-20000/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-17000] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5000\n",
            "  Batch size = 42\n",
            "Saving model checkpoint to ./results/checkpoint-21000\n",
            "Configuration saved in ./results/checkpoint-21000/config.json\n",
            "Model weights saved in ./results/checkpoint-21000/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-18000] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5000\n",
            "  Batch size = 42\n",
            "Saving model checkpoint to ./results/checkpoint-22000\n",
            "Configuration saved in ./results/checkpoint-22000/config.json\n",
            "Model weights saved in ./results/checkpoint-22000/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-19000] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5000\n",
            "  Batch size = 42\n",
            "Saving model checkpoint to ./results/checkpoint-23000\n",
            "Configuration saved in ./results/checkpoint-23000/config.json\n",
            "Model weights saved in ./results/checkpoint-23000/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-20000] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5000\n",
            "  Batch size = 42\n",
            "Saving model checkpoint to ./results/checkpoint-24000\n",
            "Configuration saved in ./results/checkpoint-24000/config.json\n",
            "Model weights saved in ./results/checkpoint-24000/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-21000] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5000\n",
            "  Batch size = 42\n",
            "Saving model checkpoint to ./results/checkpoint-25000\n",
            "Configuration saved in ./results/checkpoint-25000/config.json\n",
            "Model weights saved in ./results/checkpoint-25000/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-22000] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5000\n",
            "  Batch size = 42\n",
            "Saving model checkpoint to ./results/checkpoint-26000\n",
            "Configuration saved in ./results/checkpoint-26000/config.json\n",
            "Model weights saved in ./results/checkpoint-26000/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-23000] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5000\n",
            "  Batch size = 42\n",
            "Saving model checkpoint to ./results/checkpoint-27000\n",
            "Configuration saved in ./results/checkpoint-27000/config.json\n",
            "Model weights saved in ./results/checkpoint-27000/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-24000] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5000\n",
            "  Batch size = 42\n",
            "Saving model checkpoint to ./results/checkpoint-28000\n",
            "Configuration saved in ./results/checkpoint-28000/config.json\n",
            "Model weights saved in ./results/checkpoint-28000/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-25000] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5000\n",
            "  Batch size = 42\n",
            "Saving model checkpoint to ./results/checkpoint-29000\n",
            "Configuration saved in ./results/checkpoint-29000/config.json\n",
            "Model weights saved in ./results/checkpoint-29000/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-26000] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5000\n",
            "  Batch size = 42\n",
            "Saving model checkpoint to ./results/checkpoint-30000\n",
            "Configuration saved in ./results/checkpoint-30000/config.json\n",
            "Model weights saved in ./results/checkpoint-30000/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-27000] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5000\n",
            "  Batch size = 42\n",
            "Saving model checkpoint to ./results/checkpoint-31000\n",
            "Configuration saved in ./results/checkpoint-31000/config.json\n",
            "Model weights saved in ./results/checkpoint-31000/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-28000] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5000\n",
            "  Batch size = 42\n",
            "Saving model checkpoint to ./results/checkpoint-32000\n",
            "Configuration saved in ./results/checkpoint-32000/config.json\n",
            "Model weights saved in ./results/checkpoint-32000/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-29000] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5000\n",
            "  Batch size = 42\n",
            "Saving model checkpoint to ./results/checkpoint-33000\n",
            "Configuration saved in ./results/checkpoint-33000/config.json\n",
            "Model weights saved in ./results/checkpoint-33000/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-30000] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5000\n",
            "  Batch size = 42\n",
            "Saving model checkpoint to ./results/checkpoint-34000\n",
            "Configuration saved in ./results/checkpoint-34000/config.json\n",
            "Model weights saved in ./results/checkpoint-34000/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-31000] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5000\n",
            "  Batch size = 42\n",
            "Saving model checkpoint to ./results/checkpoint-35000\n",
            "Configuration saved in ./results/checkpoint-35000/config.json\n",
            "Model weights saved in ./results/checkpoint-35000/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-32000] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5000\n",
            "  Batch size = 42\n",
            "Saving model checkpoint to ./results/checkpoint-36000\n",
            "Configuration saved in ./results/checkpoint-36000/config.json\n",
            "Model weights saved in ./results/checkpoint-36000/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-33000] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5000\n",
            "  Batch size = 42\n",
            "Saving model checkpoint to ./results/checkpoint-37000\n",
            "Configuration saved in ./results/checkpoint-37000/config.json\n",
            "Model weights saved in ./results/checkpoint-37000/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-34000] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5000\n",
            "  Batch size = 42\n",
            "Saving model checkpoint to ./results/checkpoint-38000\n",
            "Configuration saved in ./results/checkpoint-38000/config.json\n",
            "Model weights saved in ./results/checkpoint-38000/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-35000] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5000\n",
            "  Batch size = 42\n",
            "Saving model checkpoint to ./results/checkpoint-39000\n",
            "Configuration saved in ./results/checkpoint-39000/config.json\n",
            "Model weights saved in ./results/checkpoint-39000/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-36000] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5000\n",
            "  Batch size = 42\n",
            "Saving model checkpoint to ./results/checkpoint-40000\n",
            "Configuration saved in ./results/checkpoint-40000/config.json\n",
            "Model weights saved in ./results/checkpoint-40000/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-37000] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5000\n",
            "  Batch size = 42\n",
            "Saving model checkpoint to ./results/checkpoint-41000\n",
            "Configuration saved in ./results/checkpoint-41000/config.json\n",
            "Model weights saved in ./results/checkpoint-41000/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-38000] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5000\n",
            "  Batch size = 42\n",
            "Saving model checkpoint to ./results/checkpoint-42000\n",
            "Configuration saved in ./results/checkpoint-42000/config.json\n",
            "Model weights saved in ./results/checkpoint-42000/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-39000] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5000\n",
            "  Batch size = 42\n",
            "Saving model checkpoint to ./results/checkpoint-43000\n",
            "Configuration saved in ./results/checkpoint-43000/config.json\n",
            "Model weights saved in ./results/checkpoint-43000/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-40000] due to args.save_total_limit\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from ./results/checkpoint-43000 (score: 0.9843953251838684).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=43940, training_loss=1.352063531402463, metrics={'train_runtime': 25092.3339, 'train_samples_per_second': 73.541, 'train_steps_per_second': 1.751, 'total_flos': 4.9398388200032256e+17, 'train_loss': 1.352063531402463, 'epoch': 4.0})"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Upload model to huggingface hub"
      ],
      "metadata": {
        "id": "S4guAIJ4oEOl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install git-lfs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZWuBagelDWl",
        "outputId": "7c78dfa7-9401-4e4c-e540-a40ca90d972a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  git-lfs\n",
            "0 upgraded, 1 newly installed, 0 to remove and 37 not upgraded.\n",
            "Need to get 2,129 kB of archives.\n",
            "After this operation, 7,662 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 git-lfs amd64 2.3.4-1 [2,129 kB]\n",
            "Fetched 2,129 kB in 1s (2,347 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package git-lfs.\n",
            "(Reading database ... 155222 files and directories currently installed.)\n",
            "Preparing to unpack .../git-lfs_2.3.4-1_amd64.deb ...\n",
            "Unpacking git-lfs (2.3.4-1) ...\n",
            "Setting up git-lfs (2.3.4-1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git lfs install"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yI-GbReWlLy5",
        "outputId": "4a218bd4-136b-444e-a8e5-44a320455a99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: Failed to call git rev-parse --git-dir --show-toplevel: \"fatal: not a git repository (or any of the parent directories): .git\\n\"\n",
            "Git LFS initialized.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# first, download and use git-lfs: https://askubuntu.com/questions/799341/how-to-install-git-lfs-on-ubuntu-16-04\n",
        "model.push_to_hub(\"kogpt-conditional-2\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278,
          "referenced_widgets": [
            "835ffafa53714ab1aa650b8158df0bae",
            "5e25f6813d9e48098c32707d462c2eae",
            "54a53bf5743e4055921c203edc6d737d",
            "4a56664acfb24bc1a3bb75a83d9386f3",
            "6bcfb5608f834193abf15a1299f17ed2",
            "c54ce33210154cca8d336f854c54ae02",
            "987daf984f3a4a109e495a6089248bf3",
            "503ba1adcfb24b8ba4a57cec09dfe3a0",
            "12266d0755d444a397780bc1c324bb54",
            "f55e65b6f3ae49a0aa789b8607dc762e",
            "926916ca67274048bb911bd6c3bc0982"
          ]
        },
        "id": "Iw7LDGyUj3iA",
        "outputId": "d3082ad1-4121-4a63-e8e2-dea72778d08c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/huggingface_hub/hf_api.py:726: FutureWarning: `create_repo` now takes `token` as an optional positional argument. Be sure to adapt your code!\n",
            "  FutureWarning,\n",
            "Cloning https://huggingface.co/snoop2head/kogpt-conditional-2 into local empty directory.\n",
            "Configuration saved in kogpt-conditional-2/config.json\n",
            "Model weights saved in kogpt-conditional-2/pytorch_model.bin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "835ffafa53714ab1aa650b8158df0bae",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Upload file pytorch_model.bin:   0%|          | 3.38k/4.35G [00:09<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "To https://huggingface.co/snoop2head/kogpt-conditional-2\n",
            "   ea0f530..5016395  main -> main\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'https://huggingface.co/snoop2head/kogpt-conditional-2/commit/50163955ec8ec7dff649e11a0f83d2101b8a41b6'"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference with the model"
      ],
      "metadata": {
        "id": "XcOWH7wXIiJ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available() and CFG.DEBUG == False:\n",
        "    device = torch.device(\"cuda:0\")\n",
        "elif CFG.DEBUG == True:\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "print(f\"current device that is inferencing on: {device}\")\n",
        "\n",
        "model.to(device)\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2mWd2RPQMV3w",
        "outputId": "c6678111-2702-4204-e4cf-a04ac6c715bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "current device that is inferencing on: cuda:0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPT2LMHeadModel(\n",
              "  (transformer): GPT2Model(\n",
              "    (wte): Embedding(51200, 1920)\n",
              "    (wpe): Embedding(1024, 1920)\n",
              "    (drop): Dropout(p=0.1, inplace=False)\n",
              "    (h): ModuleList(\n",
              "      (0): GPT2Block(\n",
              "        (ln_1): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): GPT2Block(\n",
              "        (ln_1): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (2): GPT2Block(\n",
              "        (ln_1): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (3): GPT2Block(\n",
              "        (ln_1): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (4): GPT2Block(\n",
              "        (ln_1): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (5): GPT2Block(\n",
              "        (ln_1): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (6): GPT2Block(\n",
              "        (ln_1): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (7): GPT2Block(\n",
              "        (ln_1): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (8): GPT2Block(\n",
              "        (ln_1): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (9): GPT2Block(\n",
              "        (ln_1): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (10): GPT2Block(\n",
              "        (ln_1): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (11): GPT2Block(\n",
              "        (ln_1): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (12): GPT2Block(\n",
              "        (ln_1): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (13): GPT2Block(\n",
              "        (ln_1): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (14): GPT2Block(\n",
              "        (ln_1): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (15): GPT2Block(\n",
              "        (ln_1): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (16): GPT2Block(\n",
              "        (ln_1): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (17): GPT2Block(\n",
              "        (ln_1): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (18): GPT2Block(\n",
              "        (ln_1): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (19): GPT2Block(\n",
              "        (ln_1): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (20): GPT2Block(\n",
              "        (ln_1): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (21): GPT2Block(\n",
              "        (ln_1): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (22): GPT2Block(\n",
              "        (ln_1): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (23): GPT2Block(\n",
              "        (ln_1): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_f): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=1920, out_features=51200, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create condition sentence\n",
        "# please refer to wrangle_logit.ipynb for statistics\n",
        "random_main_logit = np.random.normal(\n",
        "    loc=3.368,\n",
        "    scale=1.015,\n",
        "    size=1\n",
        "    )[0].round(1)\n",
        "random_sub_logit = np.random.normal(\n",
        "    loc=1.333,\n",
        "    scale=0.790,\n",
        "    size=1\n",
        "    )[0].round(1)\n",
        "condition_sentence = f\"{random_main_logit}만큼 행복감정인 문장이다. {random_sub_logit}만큼 놀람감정인 문장이다. \"\n",
        "\n",
        "# make input sentence\n",
        "input_sentence = \"수상한 밤들이 계속되던 날, 언젠가부터 나는\"\n",
        "condition_plus_input = condition_sentence + input_sentence\n",
        "print(condition_plus_input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uqIBDRJlH4Ic",
        "outputId": "4baec286-4010-4700-db9f-9c69a9e87a42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.9만큼 행복감정인 문장이다. 1.2만큼 놀람감정인 문장이다. 수상한 밤들이 계속되던 날, 언젠가부터 나는\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def infer_sentence(input_sentence, k, output_token_length):\n",
        "\n",
        "    # encode the sample sentence\n",
        "    input_ids = tokenizer.encode(\n",
        "        input_sentence, \n",
        "        add_special_tokens=False, \n",
        "        return_tensors=\"pt\"\n",
        "        ) # 나는 밥을 먹었다 -> [32, 2, 50, 3, 90, 12, 15]\n",
        "\n",
        "    # decode the output sequence and print its outcome\n",
        "    list_decoded_sequences = []\n",
        "    while len(list_decoded_sequences) < k:\n",
        "        # generate output sequence from the given encoded input sequence\n",
        "        output_sequences = model.generate(\n",
        "            input_ids=input_ids.to(device), \n",
        "            do_sample=True, \n",
        "            max_length=output_token_length, \n",
        "            num_return_sequences=k\n",
        "            )\n",
        "\n",
        "        for index, generated_sequence in enumerate(output_sequences):\n",
        "            generated_sequence = generated_sequence.tolist()\n",
        "            # remove padding from the generated sequence\n",
        "            generated_sequence = generated_sequence[:generated_sequence.index(tokenizer.pad_token_id)] # #45, #65, #78 | # 1, #1, #1, #1, #1, #1, #1,  \n",
        "            decoded_sequence = tokenizer.decode(generated_sequence, clean_up_tokenization_spaces=True) # decoding: input_id -> token\n",
        "            # print(f\"{index} : {decoded_sequence}\")\n",
        "            list_decoded_sequences.append(decoded_sequence)\n",
        "        list_decoded_sequences = list(set(list_decoded_sequences))\n",
        "    \n",
        "    return list_decoded_sequences"
      ],
      "metadata": {
        "id": "USZCTG3GKEG9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inferred_sentence = infer_sentence(condition_plus_input, k=10, output_token_length=CFG.max_token_length)\n",
        "inferred_sentence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B3lnVuPPKIdO",
        "outputId": "61335768-5ffe-48ab-fb8e-c0dc8e0c0884"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['3.9만큼 행복감정인 문장이다. 1.2만큼 놀람감정인 문장이다. 수상한 밤들이 계속되던 날, 언젠가부터 나는 서서히 제정신을 차리고 일어날 수 있었다',\n",
              " '3.9만큼 행복감정인 문장이다. 1.2만큼 놀람감정인 문장이다. 수상한 밤들이 계속되던 날, 언젠가부터 나는 달 보는 걸 좋아하게 되었다',\n",
              " '3.9만큼 행복감정인 문장이다. 1.2만큼 놀람감정인 문장이다. 수상한 밤들이 계속되던 날, 언젠가부터 나는 수상한 사람들의 입을 들여다 볼 수 있었다',\n",
              " '3.9만큼 행복감정인 문장이다. 1.2만큼 놀람감정인 문장이다. 수상한 밤들이 계속되던 날, 언젠가부터 나는 이상한 나라의 앨리스가 되어 있었다',\n",
              " '3.9만큼 행복감정인 문장이다. 1.2만큼 놀람감정인 문장이다. 수상한 밤들이 계속되던 날, 언젠가부터 나는 기이한 경험을 했다',\n",
              " '3.9만큼 행복감정인 문장이다. 1.2만큼 놀람감정인 문장이다. 수상한 밤들이 계속되던 날, 언젠가부터 나는 이상하게도 평화가 찾아온다는 사실을 깨달았다',\n",
              " '3.9만큼 행복감정인 문장이다. 1.2만큼 놀람감정인 문장이다. 수상한 밤들이 계속되던 날, 언젠가부터 나는 어둠을 뚫는 무언가가 있다는 걸 알았다',\n",
              " '3.9만큼 행복감정인 문장이다. 1.2만큼 놀람감정인 문장이다. 수상한 밤들이 계속되던 날, 언젠가부터 나는 달빛의 의미를 이해하기 시작했다',\n",
              " '3.9만큼 행복감정인 문장이다. 1.2만큼 놀람감정인 문장이다. 수상한 밤들이 계속되던 날, 언젠가부터 나는 안방에서 잘 때 내 손을 꼭 잡았다',\n",
              " '3.9만큼 행복감정인 문장이다. 1.2만큼 놀람감정인 문장이다. 수상한 밤들이 계속되던 날, 언젠가부터 나는 이상한 나라의 앨리스처럼 눈을 반짝이며 주위를 탐구하기 시작했다']"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clear up GPU"
      ],
      "metadata": {
        "id": "SAe00zxjoVVB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.cpu()\n",
        "del model\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "m21JfwIlLKrW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del training_args\n",
        "del trainer\n",
        "del kor_poetic_dataloader"
      ],
      "metadata": {
        "id": "fOk1wsHKocBA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del kor_poetic_dataset"
      ],
      "metadata": {
        "id": "XCOExTruodT-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}